{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from itertools import chain\n",
    "from numpy import expand_dims\n",
    "from torchvision import *\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import FastText\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CUDA_LAUNCH_BLOCKING=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        d = {}\n",
    "        for x in lines:\n",
    "            idx = 0\n",
    "            if x.split(' ')[-1] != 'O\\n':\n",
    "                idx=1\n",
    "            temp = x.split(' ')[0].lower()\n",
    "            if temp in d and d[temp]==0:\n",
    "                continue\n",
    "            else:\n",
    "                d[temp]=idx\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = make_dict(r'train.txt')\n",
    "main_dict_valid = make_dict(r'valid.txt')\n",
    "main_dict_test = make_dict(r'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'-docstart-': 0,\n",
       "  '\\n': 1,\n",
       "  'eu': 1,\n",
       "  'rejects': 0,\n",
       "  'german': 1,\n",
       "  'call': 0,\n",
       "  'to': 0,\n",
       "  'boycott': 0,\n",
       "  'british': 1,\n",
       "  'lamb': 0,\n",
       "  '.': 0,\n",
       "  'peter': 1,\n",
       "  'blackburn': 1,\n",
       "  'brussels': 1,\n",
       "  '1996-08-22': 0,\n",
       "  'the': 0,\n",
       "  'european': 1,\n",
       "  'commission': 0,\n",
       "  'said': 0,\n",
       "  'on': 0,\n",
       "  'thursday': 0,\n",
       "  'it': 0,\n",
       "  'disagreed': 0,\n",
       "  'with': 0,\n",
       "  'advice': 0,\n",
       "  'consumers': 0,\n",
       "  'shun': 0,\n",
       "  'until': 0,\n",
       "  'scientists': 0,\n",
       "  'determine': 0,\n",
       "  'whether': 0,\n",
       "  'mad': 0,\n",
       "  'cow': 0,\n",
       "  'disease': 0,\n",
       "  'can': 0,\n",
       "  'be': 0,\n",
       "  'transmitted': 0,\n",
       "  'sheep': 0,\n",
       "  'germany': 1,\n",
       "  \"'s\": 0,\n",
       "  'representative': 0,\n",
       "  'union': 0,\n",
       "  'veterinary': 0,\n",
       "  'committee': 0,\n",
       "  'werner': 1,\n",
       "  'zwingmann': 1,\n",
       "  'wednesday': 0,\n",
       "  'should': 0,\n",
       "  'buy': 0,\n",
       "  'sheepmeat': 0,\n",
       "  'from': 0,\n",
       "  'countries': 0,\n",
       "  'other': 0,\n",
       "  'than': 0,\n",
       "  'britain': 1,\n",
       "  'scientific': 0,\n",
       "  'was': 0,\n",
       "  'clearer': 0,\n",
       "  '\"': 0,\n",
       "  'we': 0,\n",
       "  'do': 0,\n",
       "  \"n't\": 0,\n",
       "  'support': 0,\n",
       "  'any': 0,\n",
       "  'such': 0,\n",
       "  'recommendation': 0,\n",
       "  'because': 0,\n",
       "  'see': 0,\n",
       "  'grounds': 0,\n",
       "  'for': 0,\n",
       "  ',': 0,\n",
       "  'chief': 0,\n",
       "  'spokesman': 0,\n",
       "  'nikolaus': 1,\n",
       "  'van': 0,\n",
       "  'der': 1,\n",
       "  'pas': 1,\n",
       "  'told': 0,\n",
       "  'a': 0,\n",
       "  'news': 0,\n",
       "  'briefing': 0,\n",
       "  'he': 0,\n",
       "  'further': 0,\n",
       "  'study': 0,\n",
       "  'required': 0,\n",
       "  'and': 0,\n",
       "  'if': 0,\n",
       "  'found': 0,\n",
       "  'that': 0,\n",
       "  'action': 0,\n",
       "  'needed': 0,\n",
       "  'taken': 0,\n",
       "  'by': 0,\n",
       "  'proposal': 0,\n",
       "  'last': 0,\n",
       "  'month': 0,\n",
       "  'farm': 0,\n",
       "  'commissioner': 0,\n",
       "  'franz': 1,\n",
       "  'fischler': 1,\n",
       "  'ban': 0,\n",
       "  'brains': 0,\n",
       "  'spleens': 0,\n",
       "  'spinal': 0,\n",
       "  'cords': 0,\n",
       "  'human': 0,\n",
       "  'animal': 0,\n",
       "  'food': 0,\n",
       "  'chains': 0,\n",
       "  'highly': 0,\n",
       "  'specific': 0,\n",
       "  'precautionary': 0,\n",
       "  'move': 0,\n",
       "  'protect': 0,\n",
       "  'health': 0,\n",
       "  'proposed': 0,\n",
       "  'eu-wide': 1,\n",
       "  'measures': 0,\n",
       "  'after': 0,\n",
       "  'reports': 0,\n",
       "  'france': 1,\n",
       "  'under': 0,\n",
       "  'laboratory': 0,\n",
       "  'conditions': 0,\n",
       "  'could': 0,\n",
       "  'contract': 0,\n",
       "  'bovine': 0,\n",
       "  'spongiform': 0,\n",
       "  'encephalopathy': 0,\n",
       "  '(': 0,\n",
       "  'bse': 1,\n",
       "  ')': 0,\n",
       "  '--': 0,\n",
       "  'but': 0,\n",
       "  'agreed': 0,\n",
       "  'review': 0,\n",
       "  'his': 0,\n",
       "  'standing': 0,\n",
       "  'mational': 0,\n",
       "  'officials': 0,\n",
       "  'questioned': 0,\n",
       "  'justified': 0,\n",
       "  'as': 0,\n",
       "  'there': 0,\n",
       "  'only': 0,\n",
       "  'slight': 0,\n",
       "  'risk': 0,\n",
       "  'spanish': 1,\n",
       "  'minister': 0,\n",
       "  'loyola': 1,\n",
       "  'de': 0,\n",
       "  'palacio': 1,\n",
       "  'had': 0,\n",
       "  'earlier': 0,\n",
       "  'accused': 0,\n",
       "  'at': 0,\n",
       "  'an': 0,\n",
       "  'ministers': 0,\n",
       "  \"'\": 0,\n",
       "  'meeting': 0,\n",
       "  'of': 0,\n",
       "  'causing': 0,\n",
       "  'unjustified': 0,\n",
       "  'alarm': 0,\n",
       "  'through': 0,\n",
       "  'dangerous': 0,\n",
       "  'generalisation': 0,\n",
       "  'backed': 0,\n",
       "  'multidisciplinary': 0,\n",
       "  'committees': 0,\n",
       "  'are': 0,\n",
       "  'due': 0,\n",
       "  're-examine': 0,\n",
       "  'issue': 0,\n",
       "  'early': 0,\n",
       "  'next': 0,\n",
       "  'make': 0,\n",
       "  'recommendations': 0,\n",
       "  'senior': 0,\n",
       "  'have': 0,\n",
       "  'long': 0,\n",
       "  'been': 0,\n",
       "  'known': 0,\n",
       "  'scrapie': 0,\n",
       "  'brain-wasting': 0,\n",
       "  'similar': 0,\n",
       "  'which': 0,\n",
       "  'is': 0,\n",
       "  'believed': 0,\n",
       "  'transferred': 0,\n",
       "  'cattle': 0,\n",
       "  'feed': 0,\n",
       "  'containing': 0,\n",
       "  'waste': 0,\n",
       "  'farmers': 0,\n",
       "  'denied': 0,\n",
       "  'danger': 0,\n",
       "  'their': 0,\n",
       "  'expressed': 0,\n",
       "  'concern': 0,\n",
       "  'government': 0,\n",
       "  'avoid': 0,\n",
       "  'might': 0,\n",
       "  'influence': 0,\n",
       "  'across': 0,\n",
       "  'europe': 1,\n",
       "  'what': 0,\n",
       "  'extremely': 0,\n",
       "  'careful': 0,\n",
       "  'how': 0,\n",
       "  'going': 0,\n",
       "  'take': 0,\n",
       "  'lead': 0,\n",
       "  'welsh': 1,\n",
       "  'national': 0,\n",
       "  'nfu': 1,\n",
       "  'chairman': 0,\n",
       "  'john': 1,\n",
       "  'lloyd': 1,\n",
       "  'jones': 1,\n",
       "  'bbc': 1,\n",
       "  'radio': 0,\n",
       "  'bonn': 1,\n",
       "  'has': 0,\n",
       "  'led': 0,\n",
       "  'efforts': 0,\n",
       "  'public': 0,\n",
       "  'consumer': 0,\n",
       "  'confidence': 0,\n",
       "  'collapsed': 0,\n",
       "  'in': 0,\n",
       "  'march': 0,\n",
       "  'report': 0,\n",
       "  'suggested': 0,\n",
       "  'humans': 0,\n",
       "  'illness': 0,\n",
       "  'eating': 0,\n",
       "  'contaminated': 0,\n",
       "  'beef': 0,\n",
       "  'imported': 0,\n",
       "  '47,600': 0,\n",
       "  'year': 0,\n",
       "  'nearly': 0,\n",
       "  'half': 0,\n",
       "  'total': 0,\n",
       "  'imports': 0,\n",
       "  'brought': 0,\n",
       "  '4,275': 0,\n",
       "  'tonnes': 0,\n",
       "  'mutton': 0,\n",
       "  'some': 0,\n",
       "  '10': 0,\n",
       "  'percent': 0,\n",
       "  'overall': 0,\n",
       "  'rare': 0,\n",
       "  'hendrix': 1,\n",
       "  'song': 0,\n",
       "  'draft': 0,\n",
       "  'sells': 0,\n",
       "  'almost': 0,\n",
       "  '$': 0,\n",
       "  '17,000': 0,\n",
       "  'london': 1,\n",
       "  'handwritten': 0,\n",
       "  'u.s.': 1,\n",
       "  'guitar': 0,\n",
       "  'legend': 0,\n",
       "  'jimi': 1,\n",
       "  'sold': 0,\n",
       "  'auction': 0,\n",
       "  'late': 0,\n",
       "  'musician': 0,\n",
       "  'favourite': 0,\n",
       "  'possessions': 0,\n",
       "  'florida': 1,\n",
       "  'restaurant': 0,\n",
       "  'paid': 0,\n",
       "  '10,925': 0,\n",
       "  'pounds': 0,\n",
       "  '16,935': 0,\n",
       "  'ai': 1,\n",
       "  'no': 0,\n",
       "  'telling': 0,\n",
       "  'penned': 0,\n",
       "  'piece': 0,\n",
       "  'hotel': 0,\n",
       "  'stationery': 0,\n",
       "  '1966': 0,\n",
       "  'end': 0,\n",
       "  'january': 0,\n",
       "  '1967': 0,\n",
       "  'concert': 0,\n",
       "  'english': 1,\n",
       "  'city': 0,\n",
       "  'nottingham': 1,\n",
       "  'threw': 0,\n",
       "  'sheet': 0,\n",
       "  'paper': 0,\n",
       "  'into': 0,\n",
       "  'audience': 0,\n",
       "  'where': 0,\n",
       "  'retrieved': 0,\n",
       "  'fan': 0,\n",
       "  'buyers': 0,\n",
       "  'also': 0,\n",
       "  'snapped': 0,\n",
       "  'up': 0,\n",
       "  '16': 0,\n",
       "  'items': 0,\n",
       "  'were': 0,\n",
       "  'put': 0,\n",
       "  'former': 0,\n",
       "  'girlfriend': 0,\n",
       "  'kathy': 1,\n",
       "  'etchingham': 1,\n",
       "  'who': 0,\n",
       "  'lived': 0,\n",
       "  'him': 0,\n",
       "  '1969': 0,\n",
       "  'they': 0,\n",
       "  'included': 0,\n",
       "  'black': 0,\n",
       "  'lacquer': 0,\n",
       "  'mother': 0,\n",
       "  'pearl': 0,\n",
       "  'inlaid': 0,\n",
       "  'box': 0,\n",
       "  'used': 0,\n",
       "  'store': 0,\n",
       "  'drugs': 0,\n",
       "  'anonymous': 0,\n",
       "  'australian': 1,\n",
       "  'purchaser': 0,\n",
       "  'bought': 0,\n",
       "  '5,060': 0,\n",
       "  '7,845': 0,\n",
       "  'guitarist': 0,\n",
       "  'died': 0,\n",
       "  'overdose': 0,\n",
       "  '1970': 0,\n",
       "  'aged': 0,\n",
       "  '27': 0,\n",
       "  'china': 1,\n",
       "  'says': 0,\n",
       "  'taiwan': 1,\n",
       "  'spoils': 0,\n",
       "  'atmosphere': 0,\n",
       "  'talks': 0,\n",
       "  'beijing': 1,\n",
       "  'taipei': 1,\n",
       "  'spoiling': 0,\n",
       "  'resumption': 0,\n",
       "  'strait': 0,\n",
       "  'visit': 0,\n",
       "  'ukraine': 1,\n",
       "  'taiwanese': 1,\n",
       "  'vice': 0,\n",
       "  'president': 0,\n",
       "  'lien': 1,\n",
       "  'chan': 1,\n",
       "  'this': 0,\n",
       "  'week': 0,\n",
       "  'infuriated': 0,\n",
       "  'speaking': 0,\n",
       "  'hours': 0,\n",
       "  'chinese': 1,\n",
       "  'state': 0,\n",
       "  'media': 0,\n",
       "  'time': 0,\n",
       "  'right': 0,\n",
       "  'engage': 0,\n",
       "  'political': 0,\n",
       "  'foreign': 0,\n",
       "  'ministry': 0,\n",
       "  'shen': 1,\n",
       "  'guofang': 1,\n",
       "  'reuters': 1,\n",
       "  ':': 0,\n",
       "  'necessary': 0,\n",
       "  'opening': 0,\n",
       "  'disrupted': 0,\n",
       "  'authorities': 0,\n",
       "  'quoted': 0,\n",
       "  'top': 0,\n",
       "  'negotiator': 0,\n",
       "  'tang': 1,\n",
       "  'shubei': 1,\n",
       "  'visiting': 0,\n",
       "  'group': 0,\n",
       "  'rivals': 0,\n",
       "  'hold': 0,\n",
       "  'now': 0,\n",
       "  'two': 0,\n",
       "  'sides': 0,\n",
       "  '...': 0,\n",
       "  'hostility': 0,\n",
       "  'overseas': 0,\n",
       "  'edition': 0,\n",
       "  'people': 0,\n",
       "  'daily': 0,\n",
       "  'saying': 0,\n",
       "  'television': 0,\n",
       "  'interview': 0,\n",
       "  'read': 0,\n",
       "  'comments': 0,\n",
       "  'gave': 0,\n",
       "  'details': 0,\n",
       "  'why': 0,\n",
       "  'considered': 0,\n",
       "  'considers': 0,\n",
       "  'renegade': 0,\n",
       "  'province': 0,\n",
       "  'opposed': 0,\n",
       "  'all': 0,\n",
       "  'gain': 0,\n",
       "  'greater': 0,\n",
       "  'international': 0,\n",
       "  'recognition': 0,\n",
       "  'rival': 0,\n",
       "  'island': 0,\n",
       "  'practical': 0,\n",
       "  'steps': 0,\n",
       "  'towards': 0,\n",
       "  'goal': 0,\n",
       "  'consultations': 0,\n",
       "  'held': 0,\n",
       "  'set': 0,\n",
       "  'format': 0,\n",
       "  'official': 0,\n",
       "  'xinhua': 1,\n",
       "  'agency': 0,\n",
       "  'executive': 0,\n",
       "  'association': 0,\n",
       "  'relations': 0,\n",
       "  'straits': 0,\n",
       "  'july': 0,\n",
       "  'car': 0,\n",
       "  'registrations': 0,\n",
       "  '14.2': 0,\n",
       "  'pct': 0,\n",
       "  'yr': 0,\n",
       "  '/': 0,\n",
       "  'frankfurt': 1,\n",
       "  'first-time': 0,\n",
       "  'motor': 0,\n",
       "  'vehicles': 0,\n",
       "  'jumped': 0,\n",
       "  'year-earlier': 0,\n",
       "  'period': 0,\n",
       "  'federal': 0,\n",
       "  'office': 0,\n",
       "  '356,725': 0,\n",
       "  'new': 0,\n",
       "  'cars': 0,\n",
       "  'registered': 0,\n",
       "  '1996': 0,\n",
       "  '304,850': 0,\n",
       "  'passenger': 0,\n",
       "  '15,613': 0,\n",
       "  'trucks': 0,\n",
       "  'figures': 0,\n",
       "  'represent': 0,\n",
       "  '13.6': 0,\n",
       "  'increase': 0,\n",
       "  '2.2': 0,\n",
       "  'decline': 0,\n",
       "  '1995': 0,\n",
       "  'motor-bike': 0,\n",
       "  'registration': 0,\n",
       "  'rose': 0,\n",
       "  '32.7': 0,\n",
       "  'growth': 0,\n",
       "  'partly': 0,\n",
       "  'increased': 0,\n",
       "  'number': 0,\n",
       "  'germans': 1,\n",
       "  'buying': 0,\n",
       "  'abroad': 0,\n",
       "  'while': 0,\n",
       "  'manufacturers': 0,\n",
       "  'domestic': 0,\n",
       "  'demand': 0,\n",
       "  'weak': 0,\n",
       "  'posted': 0,\n",
       "  'gains': 0,\n",
       "  'numbers': 0,\n",
       "  'volkswagen': 1,\n",
       "  'ag': 1,\n",
       "  'won': 0,\n",
       "  '77,719': 0,\n",
       "  'slightly': 0,\n",
       "  'more': 0,\n",
       "  'quarter': 0,\n",
       "  'opel': 1,\n",
       "  'together': 0,\n",
       "  'general': 0,\n",
       "  'motors': 1,\n",
       "  'came': 0,\n",
       "  'second': 0,\n",
       "  'place': 0,\n",
       "  '49,269': 0,\n",
       "  '16.4': 0,\n",
       "  'figure': 0,\n",
       "  'third': 0,\n",
       "  'ford': 1,\n",
       "  '35,563': 0,\n",
       "  'or': 0,\n",
       "  '11.7': 0,\n",
       "  'seat': 0,\n",
       "  'porsche': 1,\n",
       "  'fewer': 0,\n",
       "  'compared': 0,\n",
       "  '3,420': 0,\n",
       "  '5522': 0,\n",
       "  'fell': 0,\n",
       "  '554': 0,\n",
       "  '643': 0,\n",
       "  'greek': 1,\n",
       "  'socialists': 0,\n",
       "  'give': 0,\n",
       "  'green': 0,\n",
       "  'light': 0,\n",
       "  'pm': 0,\n",
       "  'elections': 0,\n",
       "  'athens': 1,\n",
       "  'socialist': 0,\n",
       "  'party': 0,\n",
       "  'bureau': 0,\n",
       "  'prime': 0,\n",
       "  'costas': 1,\n",
       "  'simitis': 1,\n",
       "  'snap': 0,\n",
       "  'its': 0,\n",
       "  'secretary': 0,\n",
       "  'skandalidis': 1,\n",
       "  'reporters': 0,\n",
       "  'announcement': 0,\n",
       "  'cabinet': 0,\n",
       "  'later': 0,\n",
       "  'dimitris': 1,\n",
       "  'kontogiannis': 1,\n",
       "  'newsroom': 0,\n",
       "  '+301': 0,\n",
       "  '3311812-4': 0,\n",
       "  'bayervb': 1,\n",
       "  'sets': 0,\n",
       "  'c$': 1,\n",
       "  '100': 0,\n",
       "  'million': 0,\n",
       "  'six-year': 0,\n",
       "  'bond': 0,\n",
       "  'following': 0,\n",
       "  'announced': 0,\n",
       "  'manager': 0,\n",
       "  'toronto': 1,\n",
       "  'dominion': 1,\n",
       "  'borrower': 0,\n",
       "  'bayerische': 1,\n",
       "  'vereinsbank': 1,\n",
       "  'amt': 0,\n",
       "  'mln': 0,\n",
       "  'coupon': 0,\n",
       "  '6.625': 0,\n",
       "  'maturity': 0,\n",
       "  '24.sep.02': 0,\n",
       "  'type': 0,\n",
       "  'straight': 0,\n",
       "  'iss': 0,\n",
       "  'price': 0,\n",
       "  '100.92': 0,\n",
       "  'pay': 0,\n",
       "  'date': 0,\n",
       "  '24.sep.96': 0,\n",
       "  'full': 0,\n",
       "  'fees': 0,\n",
       "  '1.875': 0,\n",
       "  'reoffer': 0,\n",
       "  '99.32': 0,\n",
       "  'spread': 0,\n",
       "  '+20': 0,\n",
       "  'bp': 0,\n",
       "  'moody': 0,\n",
       "  'aa1': 0,\n",
       "  'listing': 0,\n",
       "  'lux': 0,\n",
       "  'freq': 0,\n",
       "  '=': 0,\n",
       "  's&p': 1,\n",
       "  'denoms': 0,\n",
       "  'k': 0,\n",
       "  '1-10-100': 0,\n",
       "  'sale': 0,\n",
       "  'limits': 0,\n",
       "  'us': 0,\n",
       "  'uk': 1,\n",
       "  'ca': 0,\n",
       "  'neg': 0,\n",
       "  'plg': 0,\n",
       "  'crs': 0,\n",
       "  'deflt': 0,\n",
       "  'force': 0,\n",
       "  'maj': 0,\n",
       "  'gov': 0,\n",
       "  'law': 0,\n",
       "  'home': 0,\n",
       "  'ctry': 0,\n",
       "  'tax': 0,\n",
       "  'provs': 0,\n",
       "  'standard': 0,\n",
       "  'mgt': 0,\n",
       "  'und': 0,\n",
       "  '0.275': 0,\n",
       "  'sell': 0,\n",
       "  'conc': 0,\n",
       "  '1.60': 0,\n",
       "  'praecip': 0,\n",
       "  'underlying': 0,\n",
       "  'govt': 0,\n",
       "  '7.0': 0,\n",
       "  'sept': 0,\n",
       "  '2001': 0,\n",
       "  'notes': 0,\n",
       "  'joint': 0,\n",
       "  '+44': 0,\n",
       "  '171': 0,\n",
       "  '542': 0,\n",
       "  '7658': 0,\n",
       "  'venantius': 1,\n",
       "  '300': 0,\n",
       "  '1999': 0,\n",
       "  'frn': 0,\n",
       "  'floating-rate': 0,\n",
       "  'lehman': 1,\n",
       "  'brothers': 0,\n",
       "  'ab': 1,\n",
       "  'swedish': 1,\n",
       "  'mortgage': 0,\n",
       "  '-': 0,\n",
       "  '12.5': 0,\n",
       "  '21.jan.99': 0,\n",
       "  'base': 0,\n",
       "  '3m': 1,\n",
       "  'libor': 0,\n",
       "  's23.sep.96': 0,\n",
       "  'aa3': 0,\n",
       "  '99.956': 0,\n",
       "  'aa+': 0,\n",
       "  's': 0,\n",
       "  'short': 0,\n",
       "  'first': 0,\n",
       "  'jp': 1,\n",
       "  'fr': 1,\n",
       "  'yes': 0,\n",
       "  'ipma': 0,\n",
       "  '2': 0,\n",
       "  'sweden': 1,\n",
       "  '5': 0,\n",
       "  'issued': 0,\n",
       "  'off': 0,\n",
       "  'emtn': 0,\n",
       "  'programme': 0,\n",
       "  '8863': 0,\n",
       "  'port': 0,\n",
       "  'update': 0,\n",
       "  'syria': 1,\n",
       "  'lloyds': 1,\n",
       "  'shipping': 0,\n",
       "  'intelligence': 0,\n",
       "  'service': 0,\n",
       "  'lattakia': 1,\n",
       "  'aug': 0,\n",
       "  'waiting': 0,\n",
       "  'tartous': 1,\n",
       "  'presently': 0,\n",
       "  '24': 0,\n",
       "  'israel': 1,\n",
       "  'plays': 0,\n",
       "  'down': 0,\n",
       "  'fears': 0,\n",
       "  'war': 0,\n",
       "  'colleen': 1,\n",
       "  'siegel': 1,\n",
       "  'jerusalem': 1,\n",
       "  'outgoing': 0,\n",
       "  'peace': 0,\n",
       "  'current': 0,\n",
       "  'tensions': 0,\n",
       "  'between': 0,\n",
       "  'appeared': 0,\n",
       "  'storm': 0,\n",
       "  'teacup': 0,\n",
       "  'itamar': 1,\n",
       "  'rabinovich': 1,\n",
       "  'ambassador': 0,\n",
       "  'washington': 1,\n",
       "  'conducted': 0,\n",
       "  'unfruitful': 0,\n",
       "  'negotiations': 0,\n",
       "  'looked': 0,\n",
       "  'like': 0,\n",
       "  'damascus': 1,\n",
       "  'wanted': 0,\n",
       "  'talk': 0,\n",
       "  'rather': 0,\n",
       "  'fight': 0,\n",
       "  'appears': 0,\n",
       "  'me': 0,\n",
       "  'syrian': 1,\n",
       "  'priority': 0,\n",
       "  'still': 0,\n",
       "  'negotiate': 0,\n",
       "  'syrians': 1,\n",
       "  'confused': 0,\n",
       "  'definitely': 0,\n",
       "  'tense': 0,\n",
       "  'assessment': 0,\n",
       "  'here': 0,\n",
       "  'essentially': 0,\n",
       "  'winding': 0,\n",
       "  'term': 0,\n",
       "  'will': 0,\n",
       "  'replaced': 0,\n",
       "  'eliahu': 1,\n",
       "  'ben-elissar': 1,\n",
       "  'israeli': 1,\n",
       "  'envoy': 0,\n",
       "  'egypt': 1,\n",
       "  'right-wing': 0,\n",
       "  'likud': 1,\n",
       "  'politician': 0,\n",
       "  'sent': 0,\n",
       "  'message': 0,\n",
       "  'via': 0,\n",
       "  'committed': 0,\n",
       "  'open': 0,\n",
       "  'without': 0,\n",
       "  'preconditions': 0,\n",
       "  'slammed': 0,\n",
       "  'creating': 0,\n",
       "  'called': 0,\n",
       "  'launching': 0,\n",
       "  'hysterical': 0,\n",
       "  'campaign': 0,\n",
       "  'against': 0,\n",
       "  'reported': 0,\n",
       "  'recently': 0,\n",
       "  'test': 0,\n",
       "  'fired': 0,\n",
       "  'missile': 0,\n",
       "  'arms': 0,\n",
       "  'purchases': 0,\n",
       "  'defensive': 0,\n",
       "  'purposes': 0,\n",
       "  'hafez': 1,\n",
       "  'al-': 1,\n",
       "  'assad': 1,\n",
       "  'ready': 0,\n",
       "  'enter': 0,\n",
       "  'david': 1,\n",
       "  'levy': 1,\n",
       "  'tension': 0,\n",
       "  'mounted': 0,\n",
       "  'since': 0,\n",
       "  'benjamin': 1,\n",
       "  'netanyahu': 1,\n",
       "  'took': 0,\n",
       "  'june': 0,\n",
       "  'vowing': 0,\n",
       "  'retain': 0,\n",
       "  'golan': 1,\n",
       "  'heights': 1,\n",
       "  'captured': 0,\n",
       "  'middle': 0,\n",
       "  'east': 0,\n",
       "  'israeli-syrian': 1,\n",
       "  'deadlocked': 0,\n",
       "  'over': 0,\n",
       "  '1991': 0,\n",
       "  'despite': 0,\n",
       "  'previous': 0,\n",
       "  'willingness': 0,\n",
       "  'concessions': 0,\n",
       "  'february': 0,\n",
       "  'voices': 0,\n",
       "  'coming': 0,\n",
       "  'out': 0,\n",
       "  'bad': 0,\n",
       "  'not': 0,\n",
       "  'good': 0,\n",
       "  'expressions': 0,\n",
       "  'declarations': 0,\n",
       "  'must': 0,\n",
       "  'worrying': 0,\n",
       "  'artificial': 0,\n",
       "  'very': 0,\n",
       "  'those': 0,\n",
       "  'become': 0,\n",
       "  'prisoners': 0,\n",
       "  'expect': 0,\n",
       "  'face': 0,\n",
       "  'answer': 0,\n",
       "  'our': 0,\n",
       "  'want': 0,\n",
       "  'god': 1,\n",
       "  'forbid': 0,\n",
       "  'one': 0,\n",
       "  'benefits': 0,\n",
       "  'wars': 0,\n",
       "  'channel': 1,\n",
       "  'calming': 0,\n",
       "  'signal': 0,\n",
       "  'source': 0,\n",
       "  'spokesmen': 0,\n",
       "  'confirm': 0,\n",
       "  'messages': 0,\n",
       "  'reassure': 0,\n",
       "  'cairo': 1,\n",
       "  'united': 0,\n",
       "  'states': 0,\n",
       "  'moscow': 1,\n",
       "  'polish': 1,\n",
       "  'diplomat': 0,\n",
       "  'denies': 0,\n",
       "  'nurses': 0,\n",
       "  'stranded': 0,\n",
       "  'libya': 1,\n",
       "  'tunis': 1,\n",
       "  'tabloid': 0,\n",
       "  'refusing': 0,\n",
       "  'exit': 0,\n",
       "  'visas': 0,\n",
       "  'trying': 0,\n",
       "  'return': 0,\n",
       "  'working': 0,\n",
       "  'north': 0,\n",
       "  'african': 0,\n",
       "  'country': 0,\n",
       "  'true': 0,\n",
       "  'today': 0,\n",
       "  'knowledge': 0,\n",
       "  'nurse': 0,\n",
       "  'kept': 0,\n",
       "  'her': 0,\n",
       "  'received': 0,\n",
       "  'complaint': 0,\n",
       "  'embassy': 0,\n",
       "  'charge': 0,\n",
       "  \"d'affaires\": 0,\n",
       "  'tripoli': 1,\n",
       "  'tadeusz': 1,\n",
       "  'awdankiewicz': 1,\n",
       "  'telephone': 0,\n",
       "  'poland': 1,\n",
       "  'labour': 0,\n",
       "  'would': 0,\n",
       "  'send': 0,\n",
       "  'team': 0,\n",
       "  'investigate': 0,\n",
       "  'probe': 0,\n",
       "  'prompted': 0,\n",
       "  'complaining': 0,\n",
       "  'about': 0,\n",
       "  'work': 0,\n",
       "  'non-payment': 0,\n",
       "  'salaries': 0,\n",
       "  'estimated': 0,\n",
       "  '800': 0,\n",
       "  'iranian': 1,\n",
       "  'opposition': 0,\n",
       "  'leaders': 0,\n",
       "  'meet': 0,\n",
       "  'baghdad': 1,\n",
       "  'hassan': 1,\n",
       "  'hafidh': 1,\n",
       "  'exile': 0,\n",
       "  'based': 0,\n",
       "  'iraq': 1,\n",
       "  'vowed': 0,\n",
       "  'extend': 0,\n",
       "  'iran': 1,\n",
       "  'kurdish': 1,\n",
       "  'rebels': 0,\n",
       "  'attacked': 0,\n",
       "  'troops': 0,\n",
       "  'deep': 0,\n",
       "  'inside': 0,\n",
       "  'mujahideen': 1,\n",
       "  'khalq': 1,\n",
       "  'statement': 0,\n",
       "  'leader': 0,\n",
       "  'massoud': 1,\n",
       "  'rajavi': 1,\n",
       "  'met': 0,\n",
       "  'secretary-general': 0,\n",
       "  'kurdistan': 1,\n",
       "  'democratic': 0,\n",
       "  'kdpi': 1,\n",
       "  'rastegar': 1,\n",
       "  'voiced': 0,\n",
       "  'rebel': 0,\n",
       "  'kurds': 1,\n",
       "  'emphasised': 0,\n",
       "  'resistance': 0,\n",
       "  'continue': 0,\n",
       "  'stand': 0,\n",
       "  'side': 0,\n",
       "  'compatriots': 0,\n",
       "  'movement': 0,\n",
       "  'signals': 0,\n",
       "  'level': 0,\n",
       "  'cooperation': 0,\n",
       "  'oppositions': 0,\n",
       "  'heavily': 0,\n",
       "  'bombarded': 0,\n",
       "  'targets': 0,\n",
       "  'northern': 0,\n",
       "  'pursuit': 0,\n",
       "  'guerrillas': 0,\n",
       "  'iraqi': 1,\n",
       "  'areas': 0,\n",
       "  'outside': 0,\n",
       "  'control': 0,\n",
       "  'bordering': 0,\n",
       "  'patriotic': 1,\n",
       "  'puk': 1,\n",
       "  'kdp': 1,\n",
       "  'main': 0,\n",
       "  'factions': 0,\n",
       "  'forces': 0,\n",
       "  'ousted': 0,\n",
       "  'kuwait': 1,\n",
       "  'gulf': 1,\n",
       "  'clashes': 0,\n",
       "  'parties': 0,\n",
       "  'broke': 0,\n",
       "  'weekend': 0,\n",
       "  'most': 0,\n",
       "  'serious': 0,\n",
       "  'fighting': 0,\n",
       "  'u.s.-sponsored': 1,\n",
       "  'ceasefire': 0,\n",
       "  'shelling': 0,\n",
       "  'positions': 0,\n",
       "  'qasri': 1,\n",
       "  'region': 0,\n",
       "  'suleimaniya': 1,\n",
       "  'near': 0,\n",
       "  'border': 0,\n",
       "  'days': 0,\n",
       "  'killed': 0,\n",
       "  'wounded': 0,\n",
       "  'attack': 0,\n",
       "  'both': 0,\n",
       "  'turkey': 1,\n",
       "  'mount': 0,\n",
       "  'air': 0,\n",
       "  'land': 0,\n",
       "  'strikes': 0,\n",
       "  'own': 0,\n",
       "  'u.s.-led': 1,\n",
       "  'southern': 0,\n",
       "  'protects': 0,\n",
       "  'possible': 0,\n",
       "  'attacks': 0,\n",
       "  'saudi': 1,\n",
       "  'riyal': 0,\n",
       "  'rates': 0,\n",
       "  'steady': 0,\n",
       "  'quiet': 0,\n",
       "  'summer': 0,\n",
       "  'trade': 0,\n",
       "  'manama': 1,\n",
       "  'spot': 0,\n",
       "  'dollar': 0,\n",
       "  'interbank': 0,\n",
       "  'deposit': 0,\n",
       "  'mainly': 0,\n",
       "  'dealers': 0,\n",
       "  'kingdom': 0,\n",
       "  'changes': 0,\n",
       "  'market': 0,\n",
       "  'holidays': 0,\n",
       "  'dealer': 0,\n",
       "  '3.7504': 0,\n",
       "  '06': 0,\n",
       "  'one-month': 0,\n",
       "  'deposits': 0,\n",
       "  '5-1/2': 0,\n",
       "  '3/8': 0,\n",
       "  'three': 0,\n",
       "  'months': 0,\n",
       "  '5-5/8': 0,\n",
       "  '1/2': 0,\n",
       "  'six': 0,\n",
       "  '5-3/4': 0,\n",
       "  '5/8': 0,\n",
       "  'one-year': 1,\n",
       "  'funds': 0,\n",
       "  '5-7/8': 0,\n",
       "  'approves': 0,\n",
       "  ...},\n",
       " {'-docstart-': 0,\n",
       "  '\\n': 1,\n",
       "  'cricket': 0,\n",
       "  '-': 0,\n",
       "  'leicestershire': 1,\n",
       "  'take': 0,\n",
       "  'over': 0,\n",
       "  'at': 0,\n",
       "  'top': 0,\n",
       "  'after': 0,\n",
       "  'innings': 0,\n",
       "  'victory': 0,\n",
       "  '.': 0,\n",
       "  'london': 1,\n",
       "  '1996-08-30': 0,\n",
       "  'west': 0,\n",
       "  'indian': 1,\n",
       "  'all-rounder': 0,\n",
       "  'phil': 1,\n",
       "  'simmons': 1,\n",
       "  'took': 0,\n",
       "  'four': 0,\n",
       "  'for': 0,\n",
       "  '38': 0,\n",
       "  'on': 0,\n",
       "  'friday': 0,\n",
       "  'as': 0,\n",
       "  'beat': 0,\n",
       "  'somerset': 1,\n",
       "  'by': 0,\n",
       "  'an': 0,\n",
       "  'and': 0,\n",
       "  '39': 0,\n",
       "  'runs': 0,\n",
       "  'in': 0,\n",
       "  'two': 0,\n",
       "  'days': 0,\n",
       "  'to': 0,\n",
       "  'the': 0,\n",
       "  'head': 0,\n",
       "  'of': 0,\n",
       "  'county': 0,\n",
       "  'championship': 0,\n",
       "  'their': 0,\n",
       "  'stay': 0,\n",
       "  ',': 0,\n",
       "  'though': 0,\n",
       "  'may': 0,\n",
       "  'be': 0,\n",
       "  'short-lived': 0,\n",
       "  'title': 0,\n",
       "  'rivals': 0,\n",
       "  'essex': 1,\n",
       "  'derbyshire': 1,\n",
       "  'surrey': 1,\n",
       "  'all': 0,\n",
       "  'closed': 0,\n",
       "  'while': 0,\n",
       "  'kent': 1,\n",
       "  'made': 0,\n",
       "  'up': 0,\n",
       "  'lost': 0,\n",
       "  'time': 0,\n",
       "  'rain-affected': 0,\n",
       "  'match': 0,\n",
       "  'against': 0,\n",
       "  'nottinghamshire': 1,\n",
       "  'bowling': 0,\n",
       "  'out': 0,\n",
       "  '83': 0,\n",
       "  'opening': 0,\n",
       "  'morning': 0,\n",
       "  'grace': 1,\n",
       "  'road': 0,\n",
       "  'extended': 0,\n",
       "  'first': 0,\n",
       "  '94': 0,\n",
       "  'before': 0,\n",
       "  'being': 0,\n",
       "  'bowled': 0,\n",
       "  '296': 0,\n",
       "  'with': 0,\n",
       "  'england': 1,\n",
       "  'discard': 0,\n",
       "  'andy': 1,\n",
       "  'caddick': 1,\n",
       "  'taking': 0,\n",
       "  'three': 0,\n",
       "  'trailing': 0,\n",
       "  '213': 0,\n",
       "  'got': 0,\n",
       "  'a': 0,\n",
       "  'solid': 0,\n",
       "  'start': 0,\n",
       "  'second': 0,\n",
       "  'stepped': 0,\n",
       "  'bundle': 0,\n",
       "  'them': 0,\n",
       "  '174': 0,\n",
       "  'however': 0,\n",
       "  'look': 0,\n",
       "  'certain': 0,\n",
       "  'regain': 0,\n",
       "  'spot': 0,\n",
       "  'nasser': 1,\n",
       "  'hussain': 1,\n",
       "  'peter': 1,\n",
       "  'such': 0,\n",
       "  'gave': 0,\n",
       "  'firm': 0,\n",
       "  'grip': 0,\n",
       "  'yorkshire': 1,\n",
       "  'headingley': 1,\n",
       "  'considered': 0,\n",
       "  'surplus': 0,\n",
       "  \"'s\": 0,\n",
       "  'one-day': 0,\n",
       "  'requirements': 0,\n",
       "  'struck': 0,\n",
       "  '158': 0,\n",
       "  'his': 0,\n",
       "  'century': 0,\n",
       "  'season': 0,\n",
       "  'reached': 0,\n",
       "  '372': 0,\n",
       "  'lead': 0,\n",
       "  '82': 0,\n",
       "  'close': 0,\n",
       "  'had': 0,\n",
       "  'turned': 0,\n",
       "  'that': 0,\n",
       "  'into': 0,\n",
       "  '37-run': 0,\n",
       "  'advantage': 0,\n",
       "  'but': 0,\n",
       "  'off-spinner': 0,\n",
       "  'scuttled': 0,\n",
       "  'hopes': 0,\n",
       "  '24': 0,\n",
       "  '48': 0,\n",
       "  'balls': 0,\n",
       "  'leaving': 0,\n",
       "  'hanging': 0,\n",
       "  '119': 0,\n",
       "  'five': 0,\n",
       "  'praying': 0,\n",
       "  'rain': 0,\n",
       "  'oval': 1,\n",
       "  'captain': 0,\n",
       "  'chris': 1,\n",
       "  'lewis': 1,\n",
       "  'another': 0,\n",
       "  'man': 0,\n",
       "  'dumped': 0,\n",
       "  'continued': 0,\n",
       "  'silence': 0,\n",
       "  'critics': 0,\n",
       "  'he': 0,\n",
       "  'followed': 0,\n",
       "  '45': 0,\n",
       "  'thursday': 0,\n",
       "  '80': 0,\n",
       "  'not': 0,\n",
       "  'warwickshire': 1,\n",
       "  'was': 0,\n",
       "  'well': 0,\n",
       "  'backed': 0,\n",
       "  'hopeful': 0,\n",
       "  'mark': 0,\n",
       "  'butcher': 1,\n",
       "  'who': 0,\n",
       "  '70': 0,\n",
       "  '429': 0,\n",
       "  'seven': 0,\n",
       "  '234': 0,\n",
       "  'kept': 0,\n",
       "  'hunt': 0,\n",
       "  'since': 0,\n",
       "  '1936': 0,\n",
       "  'reducing': 0,\n",
       "  'worcestershire': 1,\n",
       "  '133': 0,\n",
       "  'still': 0,\n",
       "  '100': 0,\n",
       "  'away': 0,\n",
       "  'from': 0,\n",
       "  'avoiding': 0,\n",
       "  'defeat': 0,\n",
       "  'australian': 1,\n",
       "  'tom': 1,\n",
       "  'moody': 1,\n",
       "  'six': 0,\n",
       "  'adams': 1,\n",
       "  '123': 0,\n",
       "  'tim': 1,\n",
       "  \"o'gorman\": 1,\n",
       "  '109': 0,\n",
       "  '471': 0,\n",
       "  '233': 0,\n",
       "  'frustration': 0,\n",
       "  'seeing': 0,\n",
       "  'day': 0,\n",
       "  'badly': 0,\n",
       "  'affected': 0,\n",
       "  'weather': 0,\n",
       "  'gear': 0,\n",
       "  'dismiss': 0,\n",
       "  '214': 0,\n",
       "  'they': 0,\n",
       "  'were': 0,\n",
       "  'held': 0,\n",
       "  'gritty': 0,\n",
       "  '84': 0,\n",
       "  'paul': 1,\n",
       "  'johnson': 1,\n",
       "  'ex-england': 1,\n",
       "  'fast': 0,\n",
       "  'bowler': 0,\n",
       "  'martin': 1,\n",
       "  'mccague': 1,\n",
       "  '55': 0,\n",
       "  'stumps': 0,\n",
       "  '108': 0,\n",
       "  'english': 1,\n",
       "  'scores': 0,\n",
       "  'result': 0,\n",
       "  'play': 0,\n",
       "  'matches': 0,\n",
       "  ':': 0,\n",
       "  'leicester': 1,\n",
       "  '(': 0,\n",
       "  'p.': 1,\n",
       "  '4-38': 0,\n",
       "  ')': 0,\n",
       "  '22': 0,\n",
       "  'points': 0,\n",
       "  '4': 0,\n",
       "  'chester-le-street': 1,\n",
       "  'glamorgan': 1,\n",
       "  '259': 0,\n",
       "  '207': 0,\n",
       "  'a.': 1,\n",
       "  'dale': 1,\n",
       "  '69': 0,\n",
       "  'h.': 1,\n",
       "  'morris': 1,\n",
       "  ';': 0,\n",
       "  'd.': 1,\n",
       "  'blenkiron': 1,\n",
       "  '4-43': 0,\n",
       "  'durham': 1,\n",
       "  '114': 0,\n",
       "  's.': 1,\n",
       "  'watkin': 1,\n",
       "  '4-28': 0,\n",
       "  '81-3': 0,\n",
       "  'tunbridge': 1,\n",
       "  'wells': 1,\n",
       "  'm.': 1,\n",
       "  '4-55': 0,\n",
       "  '108-3': 0,\n",
       "  '195': 0,\n",
       "  '429-7': 0,\n",
       "  'c.': 1,\n",
       "  'g.': 1,\n",
       "  'kersey': 1,\n",
       "  '63': 0,\n",
       "  'j.': 1,\n",
       "  'ratcliffe': 1,\n",
       "  'bicknell': 1,\n",
       "  'hove': 1,\n",
       "  'sussex': 1,\n",
       "  '363': 0,\n",
       "  'w.': 1,\n",
       "  'athey': 1,\n",
       "  '111': 0,\n",
       "  'v.': 1,\n",
       "  'drakes': 1,\n",
       "  '52': 0,\n",
       "  'i.': 1,\n",
       "  'austin': 1,\n",
       "  '4-37': 0,\n",
       "  'lancashire': 1,\n",
       "  '197-8': 0,\n",
       "  'hegg': 1,\n",
       "  '54': 0,\n",
       "  'portsmouth': 1,\n",
       "  'middlesex': 1,\n",
       "  '199': 0,\n",
       "  '426': 0,\n",
       "  'pooley': 1,\n",
       "  'ramprakash': 1,\n",
       "  'gatting': 1,\n",
       "  'hampshire': 1,\n",
       "  '232': 0,\n",
       "  '109-5': 0,\n",
       "  'chesterfield': 1,\n",
       "  '238': 0,\n",
       "  '133-5': 0,\n",
       "  \"t.o'gorman\": 1,\n",
       "  'k.': 1,\n",
       "  'barnett': 1,\n",
       "  '87': 0,\n",
       "  't.': 1,\n",
       "  '6-82': 0,\n",
       "  'bristol': 1,\n",
       "  'gloucestershire': 1,\n",
       "  '183': 0,\n",
       "  '185-6': 0,\n",
       "  'russell': 1,\n",
       "  '56': 0,\n",
       "  'northamptonshire': 1,\n",
       "  '190': 0,\n",
       "  'curran': 1,\n",
       "  'smith': 1,\n",
       "  '5-68': 0,\n",
       "  '1997': 0,\n",
       "  'ashes': 1,\n",
       "  'intinerary': 0,\n",
       "  'australia': 1,\n",
       "  'will': 0,\n",
       "  'defend': 0,\n",
       "  'six-test': 0,\n",
       "  'series': 0,\n",
       "  'during': 0,\n",
       "  'four-month': 0,\n",
       "  'tour': 0,\n",
       "  'starting': 0,\n",
       "  '13': 0,\n",
       "  'next': 0,\n",
       "  'year': 0,\n",
       "  'test': 0,\n",
       "  'board': 0,\n",
       "  'said': 0,\n",
       "  'also': 0,\n",
       "  'internationals': 0,\n",
       "  'warm-up': 0,\n",
       "  'tourists': 0,\n",
       "  'nine': 0,\n",
       "  'first-class': 0,\n",
       "  'sides': 0,\n",
       "  'british': 1,\n",
       "  'universities': 1,\n",
       "  'minor': 1,\n",
       "  'counties': 1,\n",
       "  'scotland': 1,\n",
       "  'itinerary': 0,\n",
       "  'arrive': 0,\n",
       "  '14': 0,\n",
       "  'practice': 0,\n",
       "  'lord': 1,\n",
       "  '15': 0,\n",
       "  'v': 0,\n",
       "  'duke': 0,\n",
       "  'norfolk': 1,\n",
       "  'xi': 1,\n",
       "  'arundel': 1,\n",
       "  '17': 0,\n",
       "  'northampton': 1,\n",
       "  '18': 0,\n",
       "  '20': 0,\n",
       "  'international': 0,\n",
       "  'leeds': 1,\n",
       "  '25': 0,\n",
       "  'third': 0,\n",
       "  '27-29': 0,\n",
       "  'or': 0,\n",
       "  '31': 0,\n",
       "  'june': 0,\n",
       "  '2': 0,\n",
       "  '5-9': 0,\n",
       "  'edgbaston': 1,\n",
       "  'birmingham': 1,\n",
       "  '11-13': 0,\n",
       "  'class': 0,\n",
       "  'confirmed': 0,\n",
       "  '14-16': 0,\n",
       "  '19-23': 0,\n",
       "  '25-27': 0,\n",
       "  'oxford': 1,\n",
       "  '28-30': 0,\n",
       "  'july': 0,\n",
       "  '3-7': 0,\n",
       "  'old': 0,\n",
       "  'trafford': 1,\n",
       "  'manchester': 1,\n",
       "  '9': 0,\n",
       "  '12': 0,\n",
       "  '16-18': 0,\n",
       "  '19-21': 0,\n",
       "  '24-28': 0,\n",
       "  'fourth': 0,\n",
       "  'august': 0,\n",
       "  '1-4': 0,\n",
       "  '7-11': 0,\n",
       "  'fifth': 0,\n",
       "  'trent': 1,\n",
       "  'bridge': 1,\n",
       "  'nottingham': 1,\n",
       "  '21-25': 0,\n",
       "  'sixth': 0,\n",
       "  'soccer': 0,\n",
       "  'shearer': 1,\n",
       "  'named': 0,\n",
       "  'world': 0,\n",
       "  'costliest': 0,\n",
       "  'footballer': 0,\n",
       "  'alan': 1,\n",
       "  'new': 0,\n",
       "  '26-year-old': 0,\n",
       "  'joined': 0,\n",
       "  'newcastle': 1,\n",
       "  'million': 0,\n",
       "  'pounds': 0,\n",
       "  'sterling': 0,\n",
       "  '$': 0,\n",
       "  '23.4': 0,\n",
       "  'takes': 0,\n",
       "  'tony': 1,\n",
       "  'led': 0,\n",
       "  'side': 0,\n",
       "  'european': 1,\n",
       "  'former': 0,\n",
       "  'david': 1,\n",
       "  'platt': 1,\n",
       "  'are': 0,\n",
       "  'both': 0,\n",
       "  'injured': 0,\n",
       "  'miss': 0,\n",
       "  'cup': 1,\n",
       "  'qualifier': 0,\n",
       "  'moldova': 1,\n",
       "  'sunday': 0,\n",
       "  'captaincy': 0,\n",
       "  'trial': 0,\n",
       "  'basis': 0,\n",
       "  'coach': 0,\n",
       "  'glenn': 1,\n",
       "  'hoddle': 1,\n",
       "  'saw': 0,\n",
       "  'no': 0,\n",
       "  'reason': 0,\n",
       "  'why': 0,\n",
       "  'blackburn': 1,\n",
       "  'southampton': 1,\n",
       "  'skipper': 0,\n",
       "  'should': 0,\n",
       "  'make': 0,\n",
       "  'post': 0,\n",
       "  'own': 0,\n",
       "  '\"': 0,\n",
       "  'i': 0,\n",
       "  \"'m\": 0,\n",
       "  'sure': 0,\n",
       "  'there': 0,\n",
       "  'wo': 0,\n",
       "  \"n't\": 0,\n",
       "  'problem': 0,\n",
       "  'is': 0,\n",
       "  'job': 0,\n",
       "  'people': 0,\n",
       "  'could': 0,\n",
       "  'have': 0,\n",
       "  'done': 0,\n",
       "  'it': 0,\n",
       "  'when': 0,\n",
       "  'spoke': 0,\n",
       "  'really': 0,\n",
       "  'wanted': 0,\n",
       "  'very': 0,\n",
       "  'difficult': 0,\n",
       "  'come': 0,\n",
       "  'percent': 0,\n",
       "  'conclusion': 0,\n",
       "  'about': 0,\n",
       "  'something': 0,\n",
       "  'like': 0,\n",
       "  'this': 0,\n",
       "  '...': 0,\n",
       "  'knows': 0,\n",
       "  'how': 0,\n",
       "  'conduct': 0,\n",
       "  'himself': 0,\n",
       "  'team': 0,\n",
       "  'mates': 0,\n",
       "  'respect': 0,\n",
       "  'him': 0,\n",
       "  'situation': 0,\n",
       "  'even': 0,\n",
       "  'plays': 0,\n",
       "  'front': 0,\n",
       "  'euro': 1,\n",
       "  '96': 0,\n",
       "  'striking': 0,\n",
       "  'partner': 0,\n",
       "  'teddy': 1,\n",
       "  'sheringham': 1,\n",
       "  'withdrew': 0,\n",
       "  'squad': 0,\n",
       "  'injury': 0,\n",
       "  'probably': 0,\n",
       "  'replaced': 0,\n",
       "  'mate': 0,\n",
       "  'les': 1,\n",
       "  'ferdinand': 1,\n",
       "  'basketball': 0,\n",
       "  'tournament': 0,\n",
       "  'belgrade': 1,\n",
       "  'red': 1,\n",
       "  'star': 1,\n",
       "  'yugoslavia': 1,\n",
       "  'dinamo': 1,\n",
       "  'russia': 1,\n",
       "  '92-90': 0,\n",
       "  'halftime': 0,\n",
       "  '47-47': 0,\n",
       "  'romania': 1,\n",
       "  'lithuania': 1,\n",
       "  'under-21': 0,\n",
       "  'bucharest': 1,\n",
       "  '2-1': 0,\n",
       "  '1-1': 0,\n",
       "  'scorers': 0,\n",
       "  'cosmin': 1,\n",
       "  'contra': 1,\n",
       "  '31st': 0,\n",
       "  'mihai': 1,\n",
       "  'tararache': 1,\n",
       "  '75th': 0,\n",
       "  'danius': 1,\n",
       "  'gleveckas': 1,\n",
       "  '13rd': 0,\n",
       "  'attendance': 0,\n",
       "  '200': 0,\n",
       "  'rotor': 1,\n",
       "  'fans': 0,\n",
       "  'locked': 0,\n",
       "  'volgograd': 1,\n",
       "  'violence': 0,\n",
       "  'moscow': 1,\n",
       "  'must': 0,\n",
       "  'home': 0,\n",
       "  'game': 0,\n",
       "  'behind': 0,\n",
       "  'doors': 0,\n",
       "  'hurled': 0,\n",
       "  'bottles': 0,\n",
       "  'stones': 0,\n",
       "  'dynamo': 1,\n",
       "  'players': 0,\n",
       "  '1-0': 0,\n",
       "  'saturday': 0,\n",
       "  'ended': 0,\n",
       "  'brief': 0,\n",
       "  'spell': 0,\n",
       "  'league': 0,\n",
       "  'leaders': 0,\n",
       "  'russian': 1,\n",
       "  'disciplinary': 0,\n",
       "  'committee': 0,\n",
       "  'anatoly': 1,\n",
       "  'gorokhovsky': 1,\n",
       "  'would': 0,\n",
       "  'lada': 1,\n",
       "  'togliatti': 1,\n",
       "  'empty': 0,\n",
       "  'stands': 0,\n",
       "  'september': 0,\n",
       "  '3': 0,\n",
       "  'club': 0,\n",
       "  'put': 0,\n",
       "  'united': 0,\n",
       "  'last': 0,\n",
       "  'uefa': 1,\n",
       "  'fined': 0,\n",
       "  '1,000': 0,\n",
       "  'despite': 0,\n",
       "  'placed': 0,\n",
       "  '11': 0,\n",
       "  'games': 0,\n",
       "  'lying': 0,\n",
       "  'alania': 1,\n",
       "  'hand': 0,\n",
       "  'boxing': 0,\n",
       "  'panama': 1,\n",
       "  'roberto': 1,\n",
       "  'duran': 1,\n",
       "  'fights': 0,\n",
       "  'sands': 0,\n",
       "  'city': 0,\n",
       "  'panamanian': 1,\n",
       "  'legend': 0,\n",
       "  'hands': 0,\n",
       "  'stone': 1,\n",
       "  'climbs': 0,\n",
       "  'ring': 0,\n",
       "  'age-defying': 0,\n",
       "  'attempt': 0,\n",
       "  'sustain': 0,\n",
       "  'long': 0,\n",
       "  'career': 0,\n",
       "  'little-known': 0,\n",
       "  'mexican': 1,\n",
       "  'ariel': 1,\n",
       "  'cruz': 1,\n",
       "  '30': 0,\n",
       "  'super': 0,\n",
       "  'middleweight': 0,\n",
       "  'non-title': 0,\n",
       "  'bout': 0,\n",
       "  'fight': 0,\n",
       "  'soil': 0,\n",
       "  '10': 0,\n",
       "  'years': 0,\n",
       "  'billed': 0,\n",
       "  'here': 0,\n",
       "  'return': 0,\n",
       "  'talks': 0,\n",
       "  'if': 0,\n",
       "  'prime': 0,\n",
       "  'want': 0,\n",
       "  'prepare': 0,\n",
       "  'me': 0,\n",
       "  'feel': 0,\n",
       "  'good': 0,\n",
       "  'retiring': 0,\n",
       "  'told': 0,\n",
       "  'reuters': 1,\n",
       "  'those': 0,\n",
       "  'boxer': 0,\n",
       "  'acknowledge': 0,\n",
       "  'has': 0,\n",
       "  'won': 0,\n",
       "  'championships': 0,\n",
       "  'different': 0,\n",
       "  'weight': 0,\n",
       "  'classes': 0,\n",
       "  '--': 0,\n",
       "  'lightweight': 0,\n",
       "  'welterweight': 0,\n",
       "  'junior': 0,\n",
       "  'drawing': 0,\n",
       "  'end': 0,\n",
       "  'each': 0,\n",
       "  'frontier': 0,\n",
       "  'loses': 0,\n",
       "  'devalue': 0,\n",
       "  'position': 0,\n",
       "  'one': 0,\n",
       "  'great': 0,\n",
       "  'boxers': 0,\n",
       "  'association': 1,\n",
       "  'president': 0,\n",
       "  'ramon': 1,\n",
       "  'manzanares': 1,\n",
       "  'whose': 0,\n",
       "  '97-12': 0,\n",
       "  'record': 0,\n",
       "  'spans': 0,\n",
       "  'decades': 0,\n",
       "  'win': 0,\n",
       "  '10-round': 0,\n",
       "  'earn': 0,\n",
       "  'rematch': 0,\n",
       "  'puerto': 1,\n",
       "  'rico': 1,\n",
       "  'hector': 1,\n",
       "  'macho': 1,\n",
       "  'camacho': 1,\n",
       "  'controversial': 0,\n",
       "  'decision': 0,\n",
       "  'atlantic': 1,\n",
       "  'squash': 0,\n",
       "  'hong': 1,\n",
       "  'kong': 1,\n",
       "  'open': 0,\n",
       "  'quarter-final': 0,\n",
       "  'results': 0,\n",
       "  'prefix': 0,\n",
       "  'number': 0,\n",
       "  'denotes': 0,\n",
       "  'seeding': 0,\n",
       "  '1': 0,\n",
       "  'jansher': 0,\n",
       "  'khan': 1,\n",
       "  'pakistan': 0,\n",
       "  'cairns': 1,\n",
       "  '15-10': 0,\n",
       "  '15-6': 0,\n",
       "  '15-7': 0,\n",
       "  'anthony': 1,\n",
       "  'hill': 1,\n",
       "  'dan': 1,\n",
       "  'jenson': 1,\n",
       "  '15-9': 0,\n",
       "  '15-8': 0,\n",
       "  '15-17': 0,\n",
       "  '17-15': 0,\n",
       "  'nicol': 1,\n",
       "  '7': 0,\n",
       "  'walker': 1,\n",
       "  '15-13': 0,\n",
       "  '13-15': 0,\n",
       "  'rodney': 1,\n",
       "  'eyles': 1,\n",
       "  'derek': 1,\n",
       "  'ryan': 1,\n",
       "  'ireland': 1,\n",
       "  '11-15': 0,\n",
       "  'south': 0,\n",
       "  'korean': 1,\n",
       "  'pro-soccer': 0,\n",
       "  'seoul': 1,\n",
       "  'played': 0,\n",
       "  'pohang': 1,\n",
       "  'ulsan': 1,\n",
       "  'puchon': 1,\n",
       "  'chonbuk': 1,\n",
       "  'standings': 0,\n",
       "  'tabulate': 0,\n",
       "  'under': 0,\n",
       "  'drawn': 0,\n",
       "  'goals': 0,\n",
       "  'w': 0,\n",
       "  'd': 0,\n",
       "  'l': 0,\n",
       "  'g': 0,\n",
       "  '/': 0,\n",
       "  'f': 0,\n",
       "  'p': 0,\n",
       "  '0': 0,\n",
       "  '6': 0,\n",
       "  'chonan': 1,\n",
       "  'suwan': 1,\n",
       "  '8': 0,\n",
       "  'anyang': 1,\n",
       "  'chonnam': 1,\n",
       "  '5': 0,\n",
       "  'pusan': 1,\n",
       "  'baseball': 0,\n",
       "  'professional': 0,\n",
       "  'lg': 1,\n",
       "  'ob': 1,\n",
       "  'lotte': 1,\n",
       "  'hyundai': 1,\n",
       "  'haitai': 1,\n",
       "  'samsung': 1,\n",
       "  'hanwha': 1,\n",
       "  'ssangbangwool': 1,\n",
       "  'note': 0,\n",
       "  'winning': 0,\n",
       "  'percentage': 0,\n",
       "  'place': 0,\n",
       "  'pct': 0,\n",
       "  'gb': 0,\n",
       "  '64': 0,\n",
       "  '43': 0,\n",
       "  '.596': 0,\n",
       "  '59': 0,\n",
       "  '49': 0,\n",
       "  '.545': 0,\n",
       "  '1/2': 0,\n",
       "  '58': 0,\n",
       "  '.542': 0,\n",
       "  '57': 0,\n",
       "  '.536': 0,\n",
       "  '.468': 0,\n",
       "  '46': 0,\n",
       "  '.462': 0,\n",
       "  '.441': 0,\n",
       "  '42': 0,\n",
       "  '62': 0,\n",
       "  '.409': 0,\n",
       "  'tennis': 0,\n",
       "  'u.s.': 1,\n",
       "  'york': 1,\n",
       "  'national': 0,\n",
       "  'centre': 0,\n",
       "  'women': 0,\n",
       "  'singles': 0,\n",
       "  'round': 0,\n",
       "  'sandrine': 1,\n",
       "  'testud': 1,\n",
       "  'france': 1,\n",
       "  'ines': 1,\n",
       "  'gorrochategui': 1,\n",
       "  'argentina': 1,\n",
       "  '4-6': 0,\n",
       "  '6-2': 0,\n",
       "  '6-1': 0,\n",
       "  'men': 0,\n",
       "  'goran': 1,\n",
       "  'ivanisevic': 1,\n",
       "  'croatia': 1,\n",
       "  'scott': 1,\n",
       "  'draper': 1,\n",
       "  '6-7': 0,\n",
       "  '1-7': 0,\n",
       "  '6-3': 0,\n",
       "  '6-4': 0,\n",
       "  'henman': 1,\n",
       "  'britain': 1,\n",
       "  'doug': 1,\n",
       "  'flach': 1,\n",
       "  'philippoussis': 1,\n",
       "  'andrei': 1,\n",
       "  'olhovskiy': 1,\n",
       "  'sjeng': 1,\n",
       "  'schalken': 1,\n",
       "  'netherlands': 1,\n",
       "  'rikl': 1,\n",
       "  'czech': 1,\n",
       "  'republic': 0,\n",
       "  'guy': 1,\n",
       "  'forget': 0,\n",
       "  'felix': 1,\n",
       "  'mantilla': 1,\n",
       "  'spain': 1,\n",
       "  '7-5': 0,\n",
       "  'alexander': 1,\n",
       "  'volkov': 1,\n",
       "  'mikael': 1,\n",
       "  'tillstrom': 1,\n",
       "  'sweden': 1,\n",
       "  '1-6': 0,\n",
       "  '6-': 0,\n",
       "  '7-6': 0,\n",
       "  '10-8': 0,\n",
       "  'jonas': 1,\n",
       "  'bjorkman': 1,\n",
       "  'nainkin': 1,\n",
       "  'africa': 1,\n",
       "  'lindsay': 1,\n",
       "  'davenport': 1,\n",
       "  'anne-gaelle': 1,\n",
       "  'sidot': 1,\n",
       "  '6-0': 0,\n",
       "  'conchita': 1,\n",
       "  'martinez': 1,\n",
       "  'helena': 1,\n",
       "  'sukova': 1,\n",
       "  'amanda': 1,\n",
       "  'coetzer': 1,\n",
       "  'irina': 1,\n",
       "  'spirlea': 1,\n",
       "  'add': 0,\n",
       "  '16': 0,\n",
       "  'cedric': 1,\n",
       "  'pioline': 1,\n",
       "  'carretero': 1,\n",
       "  'alex': 1,\n",
       "  'corretja': 1,\n",
       "  'filippo': 1,\n",
       "  'veglio': 1,\n",
       "  'switzerland': 1,\n",
       "  '4-': 0,\n",
       "  'linda': 1,\n",
       "  'wild': 0,\n",
       "  'barbara': 1,\n",
       "  'rittner': 1,\n",
       "  'germany': 1,\n",
       "  'asa': 1,\n",
       "  'carlsson': 1,\n",
       "  'gabriela': 1,\n",
       "  'sabatini': 1,\n",
       "  '3-6': 0,\n",
       "  'pete': 1,\n",
       "  'sampras': 1,\n",
       "  'jiri': 1,\n",
       "  'novak': 1,\n",
       "  'haarhuis': 1,\n",
       "  'michael': 1,\n",
       "  'tebbutt': 1,\n",
       "  '1-': 0,\n",
       "  'lisa': 1,\n",
       "  'raymond': 1,\n",
       "  'kimberly': 1,\n",
       "  'po': 1,\n",
       "  'hendrik': 1,\n",
       "  'dreekmann': 1,\n",
       "  'thomas': 1,\n",
       "  'johansson': 1,\n",
       "  '7-1': 0,\n",
       "  'medvedev': 1,\n",
       "  'ukraine': 1,\n",
       "  'jan': 1,\n",
       "  'kroslak': 1,\n",
       "  'slovakia': 1,\n",
       "  'petr': 1,\n",
       "  'korda': 1,\n",
       "  'bat': 0,\n",
       "  'bohdan': 1,\n",
       "  'ulihrach': 1,\n",
       "  'monica': 1,\n",
       "  'seles': 1,\n",
       "  'dally': 1,\n",
       "  'randriantefy': 1,\n",
       "  'madagascar': 1,\n",
       "  'todd': 1,\n",
       "  'andrea': 1,\n",
       "  'gaudenzi': 1,\n",
       "  'italy': 1,\n",
       "  'stefan': 1,\n",
       "  'edberg': 1,\n",
       "  'bernd': 1,\n",
       "  'karbacher': 1,\n",
       "  'retired': 0,\n",
       "  'leg': 0,\n",
       "  'major': 0,\n",
       "  'american': 1,\n",
       "  'eastern': 0,\n",
       "  'division': 0,\n",
       "  '74': 0,\n",
       "  '.556': 0,\n",
       "  'baltimore': 1,\n",
       "  '.526': 0,\n",
       "  'boston': 1,\n",
       "  '65': 0,\n",
       "  '.515': 0,\n",
       "  'toronto': 1,\n",
       "  '71': 0,\n",
       "  '.470': 0,\n",
       "  'detroit': 1,\n",
       "  '86': 0,\n",
       "  '.358': 0,\n",
       "  '26': 0,\n",
       "  'central': 0,\n",
       "  'cleveland': 1,\n",
       "  '53': 0,\n",
       "  '.602': 0,\n",
       "  'chicago': 1,\n",
       "  'minnesota': 1,\n",
       "  '67': 0,\n",
       "  '.500': 0,\n",
       "  'milwaukee': 1,\n",
       "  '.474': 0,\n",
       "  'kansas': 1,\n",
       "  '61': 0,\n",
       "  '.452': 0,\n",
       "  'western': 0,\n",
       "  'texas': 1,\n",
       "  '75': 0,\n",
       "  '.564': 0,\n",
       "  'seattle': 1,\n",
       "  'oakland': 1,\n",
       "  '72': 0,\n",
       "  '.471': 0,\n",
       "  'california': 1,\n",
       "  '.463': 0,\n",
       "  'schedule': 0,\n",
       "  'atlanta': 1,\n",
       "  '.629': 0,\n",
       "  'montreal': 1,\n",
       "  '.538': 0,\n",
       "  'florida': 1,\n",
       "  '.478': 0,\n",
       "  '.440': 0,\n",
       "  'philadelphia': 1,\n",
       "  '.403': 0,\n",
       "  'houston': 1,\n",
       "  '.533': 0,\n",
       "  'st': 0,\n",
       "  'louis': 1,\n",
       "  'cincinnati': 1,\n",
       "  '66': 0,\n",
       "  '.496': 0,\n",
       "  'pittsburgh': 1,\n",
       "  '77': 0,\n",
       "  '.421': 0,\n",
       "  'san': 1,\n",
       "  'diego': 1,\n",
       "  '60': 0,\n",
       "  'los': 1,\n",
       "  'angeles': 1,\n",
       "  '.541': 0,\n",
       "  'colorado': 1,\n",
       "  '.519': 0,\n",
       "  'francisco': 1,\n",
       "  '.435': 0,\n",
       "  'caps': 0,\n",
       "  'tarango': 1,\n",
       "  \"o'brien\": 1,\n",
       "  'spring': 0,\n",
       "  'twin': 0,\n",
       "  'upsets': 0,\n",
       "  'lights': 0,\n",
       "  'larry': 1,\n",
       "  'fine': 0,\n",
       "  'andre': 1,\n",
       "  'agassi': 1,\n",
       "  'escaped': 0,\n",
       "  'disaster': 0,\n",
       "  'wimbledon': 1,\n",
       "  'finalist': 0,\n",
       "  'malivai': 1,\n",
       "  'washington': 1,\n",
       "  'marcelo': 1,\n",
       "  'rios': 1,\n",
       "  'so': 0,\n",
       "  'fortunate': 0,\n",
       "  ...},\n",
       " {'-docstart-': 0,\n",
       "  '\\n': 1,\n",
       "  'soccer': 0,\n",
       "  '-': 0,\n",
       "  'japan': 1,\n",
       "  'get': 0,\n",
       "  'lucky': 0,\n",
       "  'win': 0,\n",
       "  ',': 0,\n",
       "  'china': 1,\n",
       "  'in': 0,\n",
       "  'surprise': 0,\n",
       "  'defeat': 0,\n",
       "  '.': 0,\n",
       "  'nadim': 1,\n",
       "  'ladki': 1,\n",
       "  'al-ain': 1,\n",
       "  'united': 1,\n",
       "  'arab': 1,\n",
       "  'emirates': 1,\n",
       "  '1996-12-06': 0,\n",
       "  'began': 0,\n",
       "  'the': 0,\n",
       "  'defence': 0,\n",
       "  'of': 0,\n",
       "  'their': 0,\n",
       "  'asian': 1,\n",
       "  'cup': 0,\n",
       "  'title': 0,\n",
       "  'with': 0,\n",
       "  'a': 0,\n",
       "  '2-1': 0,\n",
       "  'against': 0,\n",
       "  'syria': 1,\n",
       "  'group': 0,\n",
       "  'c': 0,\n",
       "  'championship': 0,\n",
       "  'match': 0,\n",
       "  'on': 0,\n",
       "  'friday': 0,\n",
       "  'but': 0,\n",
       "  'saw': 0,\n",
       "  'luck': 0,\n",
       "  'desert': 0,\n",
       "  'them': 0,\n",
       "  'second': 0,\n",
       "  'crashing': 0,\n",
       "  'to': 0,\n",
       "  '2-0': 0,\n",
       "  'newcomers': 0,\n",
       "  'uzbekistan': 1,\n",
       "  'controlled': 0,\n",
       "  'most': 0,\n",
       "  'and': 0,\n",
       "  'several': 0,\n",
       "  'chances': 0,\n",
       "  'missed': 0,\n",
       "  'until': 0,\n",
       "  '78th': 0,\n",
       "  'minute': 0,\n",
       "  'when': 0,\n",
       "  'uzbek': 1,\n",
       "  'striker': 0,\n",
       "  'igor': 1,\n",
       "  'shkvyrin': 1,\n",
       "  'took': 0,\n",
       "  'advantage': 0,\n",
       "  'misdirected': 0,\n",
       "  'defensive': 0,\n",
       "  'header': 0,\n",
       "  'lob': 0,\n",
       "  'ball': 0,\n",
       "  'over': 0,\n",
       "  'advancing': 0,\n",
       "  'chinese': 1,\n",
       "  'keeper': 0,\n",
       "  'into': 0,\n",
       "  'an': 0,\n",
       "  'empty': 0,\n",
       "  'net': 0,\n",
       "  'oleg': 1,\n",
       "  'shatskiku': 1,\n",
       "  'made': 0,\n",
       "  'sure': 0,\n",
       "  'injury': 0,\n",
       "  'time': 0,\n",
       "  'hitting': 0,\n",
       "  'unstoppable': 0,\n",
       "  'left': 0,\n",
       "  'foot': 0,\n",
       "  'shot': 0,\n",
       "  'from': 0,\n",
       "  'just': 0,\n",
       "  'outside': 0,\n",
       "  'area': 0,\n",
       "  'former': 0,\n",
       "  'soviet': 1,\n",
       "  'republic': 0,\n",
       "  'was': 0,\n",
       "  'playing': 0,\n",
       "  'finals': 0,\n",
       "  'tie': 0,\n",
       "  'for': 0,\n",
       "  'first': 0,\n",
       "  'despite': 0,\n",
       "  'winning': 0,\n",
       "  'games': 0,\n",
       "  'two': 0,\n",
       "  'years': 0,\n",
       "  'ago': 0,\n",
       "  'are': 0,\n",
       "  'as': 0,\n",
       "  'outsiders': 0,\n",
       "  'goals': 0,\n",
       "  'errors': 0,\n",
       "  'last': 0,\n",
       "  'six': 0,\n",
       "  'minutes': 0,\n",
       "  'allowed': 0,\n",
       "  'come': 0,\n",
       "  'behind': 0,\n",
       "  'collect': 0,\n",
       "  'all': 0,\n",
       "  'three': 0,\n",
       "  'points': 0,\n",
       "  'opening': 0,\n",
       "  'meeting': 0,\n",
       "  'takuya': 1,\n",
       "  'takagi': 1,\n",
       "  'scored': 0,\n",
       "  'winner': 0,\n",
       "  '88th': 0,\n",
       "  'rising': 0,\n",
       "  'head': 0,\n",
       "  'hiroshige': 1,\n",
       "  'yanagimoto': 1,\n",
       "  'cross': 0,\n",
       "  'towards': 0,\n",
       "  'syrian': 1,\n",
       "  'goal': 0,\n",
       "  'which': 0,\n",
       "  'goalkeeper': 0,\n",
       "  'salem': 1,\n",
       "  'bitar': 1,\n",
       "  'appeared': 0,\n",
       "  'have': 0,\n",
       "  'covered': 0,\n",
       "  'then': 0,\n",
       "  'slip': 0,\n",
       "  'it': 0,\n",
       "  'costly': 0,\n",
       "  'blunder': 0,\n",
       "  'by': 0,\n",
       "  'four': 0,\n",
       "  'defender': 0,\n",
       "  'hassan': 1,\n",
       "  'abbas': 1,\n",
       "  'rose': 0,\n",
       "  'intercept': 0,\n",
       "  'long': 0,\n",
       "  '84th': 0,\n",
       "  'only': 0,\n",
       "  'managed': 0,\n",
       "  'divert': 0,\n",
       "  'top': 0,\n",
       "  'corner': 0,\n",
       "  \"'s\": 0,\n",
       "  'nader': 1,\n",
       "  'jokhadar': 1,\n",
       "  'had': 0,\n",
       "  'given': 0,\n",
       "  'lead': 0,\n",
       "  'well-struck': 0,\n",
       "  'seventh': 0,\n",
       "  'laid': 0,\n",
       "  'siege': 0,\n",
       "  'penalty': 0,\n",
       "  'game': 0,\n",
       "  'rarely': 0,\n",
       "  'breached': 0,\n",
       "  'pulled': 0,\n",
       "  'off': 0,\n",
       "  'fine': 0,\n",
       "  'saves': 0,\n",
       "  'whenever': 0,\n",
       "  'they': 0,\n",
       "  'did': 0,\n",
       "  'coach': 0,\n",
       "  'shu': 1,\n",
       "  'kamo': 1,\n",
       "  'said': 0,\n",
       "  ':': 0,\n",
       "  \"'\": 0,\n",
       "  'own': 0,\n",
       "  'proved': 0,\n",
       "  'us': 0,\n",
       "  'syrians': 1,\n",
       "  'early': 0,\n",
       "  'played': 0,\n",
       "  'defensively': 0,\n",
       "  'adopted': 0,\n",
       "  'balls': 0,\n",
       "  'hard': 0,\n",
       "  'co-hosts': 0,\n",
       "  'world': 0,\n",
       "  '2002': 0,\n",
       "  'ranked': 0,\n",
       "  '20th': 0,\n",
       "  'fifa': 1,\n",
       "  'favourites': 0,\n",
       "  'regain': 0,\n",
       "  'here': 0,\n",
       "  'hosts': 0,\n",
       "  'uae': 1,\n",
       "  'play': 0,\n",
       "  'kuwait': 1,\n",
       "  'south': 0,\n",
       "  'korea': 1,\n",
       "  'take': 0,\n",
       "  'indonesia': 1,\n",
       "  'saturday': 0,\n",
       "  'matches': 0,\n",
       "  'teams': 0,\n",
       "  'level': 0,\n",
       "  'one': 0,\n",
       "  'point': 0,\n",
       "  'each': 0,\n",
       "  'rugby': 0,\n",
       "  'union': 0,\n",
       "  'cuttitta': 1,\n",
       "  'back': 0,\n",
       "  'italy': 1,\n",
       "  'after': 0,\n",
       "  'year': 0,\n",
       "  'rome': 1,\n",
       "  'recalled': 0,\n",
       "  'marcello': 1,\n",
       "  'friendly': 0,\n",
       "  'scotland': 1,\n",
       "  'at': 0,\n",
       "  'murrayfield': 1,\n",
       "  'more': 0,\n",
       "  'than': 0,\n",
       "  '30-year-old': 0,\n",
       "  'wing': 0,\n",
       "  'announced': 0,\n",
       "  'he': 0,\n",
       "  'retiring': 0,\n",
       "  'following': 0,\n",
       "  'differences': 0,\n",
       "  'selection': 0,\n",
       "  'who': 0,\n",
       "  'trainer': 0,\n",
       "  'george': 1,\n",
       "  'coste': 1,\n",
       "  'certain': 0,\n",
       "  'week': 0,\n",
       "  'named': 0,\n",
       "  '21-man': 0,\n",
       "  'squad': 0,\n",
       "  'lacking': 0,\n",
       "  'team': 0,\n",
       "  'beaten': 0,\n",
       "  '54-21': 0,\n",
       "  'england': 1,\n",
       "  'twickenham': 1,\n",
       "  'month': 0,\n",
       "  'stefano': 1,\n",
       "  'bordon': 1,\n",
       "  'is': 0,\n",
       "  'out': 0,\n",
       "  'through': 0,\n",
       "  'illness': 0,\n",
       "  'dropped': 0,\n",
       "  'row': 0,\n",
       "  'corrado': 1,\n",
       "  'covi': 1,\n",
       "  'been': 0,\n",
       "  'five': 0,\n",
       "  'national': 0,\n",
       "  'his': 0,\n",
       "  'retirement': 0,\n",
       "  '1995': 0,\n",
       "  'where': 0,\n",
       "  'issue': 0,\n",
       "  'being': 0,\n",
       "  'side': 0,\n",
       "  'that': 0,\n",
       "  'faced': 0,\n",
       "  'pool': 0,\n",
       "  'stages': 0,\n",
       "  'approached': 0,\n",
       "  'player': 0,\n",
       "  'months': 0,\n",
       "  'about': 0,\n",
       "  'comeback': 0,\n",
       "  '\"': 0,\n",
       "  'ended': 0,\n",
       "  'wrong': 0,\n",
       "  'note': 0,\n",
       "  'i': 0,\n",
       "  'thought': 0,\n",
       "  'would': 0,\n",
       "  'be': 0,\n",
       "  'useful': 0,\n",
       "  'him': 0,\n",
       "  'available': 0,\n",
       "  'think': 0,\n",
       "  'now': 0,\n",
       "  'right': 0,\n",
       "  'return': 0,\n",
       "  'javier': 1,\n",
       "  'pertile': 1,\n",
       "  'paolo': 1,\n",
       "  'vaccari': 1,\n",
       "  'ivan': 1,\n",
       "  'francescato': 1,\n",
       "  'leandro': 1,\n",
       "  'manteri': 1,\n",
       "  'diego': 1,\n",
       "  'dominguez': 1,\n",
       "  'francesco': 1,\n",
       "  'mazzariol': 1,\n",
       "  'alessandro': 1,\n",
       "  'troncon': 1,\n",
       "  'orazio': 1,\n",
       "  'arancio': 1,\n",
       "  'andrea': 1,\n",
       "  'sgorlon': 1,\n",
       "  'massimo': 1,\n",
       "  'giovanelli': 1,\n",
       "  'carlo': 1,\n",
       "  'checchinato': 1,\n",
       "  'walter': 1,\n",
       "  'cristofoletto': 1,\n",
       "  'franco': 1,\n",
       "  'properzi': 1,\n",
       "  'curti': 1,\n",
       "  'orlandi': 1,\n",
       "  'giambatista': 1,\n",
       "  'croci': 1,\n",
       "  'gianluca': 1,\n",
       "  'guidi': 1,\n",
       "  'nicola': 1,\n",
       "  'mazzucato': 1,\n",
       "  'moscardi': 1,\n",
       "  'castellani': 1,\n",
       "  'late': 0,\n",
       "  'give': 0,\n",
       "  'gave': 0,\n",
       "  'holders': 0,\n",
       "  'uninspiring': 0,\n",
       "  'victory': 0,\n",
       "  'headed': 0,\n",
       "  'spoiled': 0,\n",
       "  'mistake-free': 0,\n",
       "  'display': 0,\n",
       "  'allowing': 0,\n",
       "  'under': 0,\n",
       "  'body': 0,\n",
       "  'taken': 0,\n",
       "  'serious': 0,\n",
       "  'attack': 0,\n",
       "  'ammar': 1,\n",
       "  'awad': 1,\n",
       "  'kenichi': 1,\n",
       "  'shimokawa': 1,\n",
       "  'disallowed': 0,\n",
       "  'offside': 0,\n",
       "  '16th': 0,\n",
       "  'later': 0,\n",
       "  'produced': 0,\n",
       "  'good': 0,\n",
       "  'double': 0,\n",
       "  'save': 0,\n",
       "  'kazuyoshi': 1,\n",
       "  'miura': 1,\n",
       "  'blocked': 0,\n",
       "  'follow-up': 0,\n",
       "  'saved': 0,\n",
       "  'well': 0,\n",
       "  'again': 0,\n",
       "  '37th': 0,\n",
       "  'parrying': 0,\n",
       "  'away': 0,\n",
       "  'started': 0,\n",
       "  'half': 0,\n",
       "  'brightly': 0,\n",
       "  'denied': 0,\n",
       "  'equaliser': 0,\n",
       "  'dived': 0,\n",
       "  'naoki': 1,\n",
       "  'soma': 1,\n",
       "  'low': 0,\n",
       "  'drive': 0,\n",
       "  '53rd': 0,\n",
       "  '19': 0,\n",
       "  '2': 0,\n",
       "  '3': 0,\n",
       "  '4': 0,\n",
       "  'masami': 1,\n",
       "  'ihara': 1,\n",
       "  '5': 0,\n",
       "  'norio': 1,\n",
       "  'omura': 1,\n",
       "  '6': 0,\n",
       "  'motohiro': 1,\n",
       "  'yamaguchi': 1,\n",
       "  '8': 0,\n",
       "  'masakiyo': 1,\n",
       "  'maezono': 1,\n",
       "  '(': 0,\n",
       "  '7': 0,\n",
       "  'yasuto': 1,\n",
       "  'honda': 1,\n",
       "  '71': 0,\n",
       "  ')': 0,\n",
       "  '9': 0,\n",
       "  '10': 0,\n",
       "  'hiroshi': 1,\n",
       "  'nanami': 1,\n",
       "  '11': 0,\n",
       "  '15': 0,\n",
       "  'hiroaki': 1,\n",
       "  'morishima': 1,\n",
       "  '14': 0,\n",
       "  'masayuki': 1,\n",
       "  'okano': 1,\n",
       "  '75': 0,\n",
       "  '24': 0,\n",
       "  'bachar': 1,\n",
       "  'srour': 1,\n",
       "  ';': 0,\n",
       "  'tarek': 1,\n",
       "  'jabban': 1,\n",
       "  'louay': 1,\n",
       "  'taleb': 1,\n",
       "  '69': 0,\n",
       "  'nihad': 1,\n",
       "  'al-boushi': 1,\n",
       "  'mohammed': 1,\n",
       "  'afash': 1,\n",
       "  '12': 0,\n",
       "  'ali': 1,\n",
       "  'dib': 1,\n",
       "  '13': 0,\n",
       "  'abdul': 1,\n",
       "  'latif': 1,\n",
       "  'helou': 1,\n",
       "  '17': 0,\n",
       "  'rihawiy': 1,\n",
       "  '46': 0,\n",
       "  'khaled': 1,\n",
       "  'zaher': 1,\n",
       "  '16': 0,\n",
       "  'freestyle': 0,\n",
       "  'skiing-world': 1,\n",
       "  'mogul': 0,\n",
       "  'results': 0,\n",
       "  'tignes': 1,\n",
       "  'france': 1,\n",
       "  'skiing': 0,\n",
       "  'moguls': 0,\n",
       "  'competition': 0,\n",
       "  'men': 0,\n",
       "  '1.': 0,\n",
       "  'jesper': 1,\n",
       "  'ronnback': 1,\n",
       "  'sweden': 1,\n",
       "  '25.76': 0,\n",
       "  '2.': 0,\n",
       "  'andrei': 1,\n",
       "  'ivanov': 1,\n",
       "  'russia': 1,\n",
       "  '24.88': 0,\n",
       "  '3.': 0,\n",
       "  'ryan': 1,\n",
       "  'johnson': 1,\n",
       "  'canada': 1,\n",
       "  '24.57': 0,\n",
       "  '4.': 0,\n",
       "  'jean-luc': 1,\n",
       "  'brassard': 1,\n",
       "  '24.40': 0,\n",
       "  '5.': 0,\n",
       "  'korneilus': 1,\n",
       "  'hole': 1,\n",
       "  'norway': 1,\n",
       "  '23.92': 0,\n",
       "  '6.': 0,\n",
       "  'jeremie': 1,\n",
       "  'collomb-patton': 1,\n",
       "  '23.87': 0,\n",
       "  '7.': 0,\n",
       "  'jim': 1,\n",
       "  'moran': 1,\n",
       "  'u.s.': 1,\n",
       "  '23.25': 0,\n",
       "  '8.': 0,\n",
       "  'dominick': 1,\n",
       "  'gauthier': 1,\n",
       "  '22.73': 0,\n",
       "  '9.': 0,\n",
       "  'johann': 1,\n",
       "  'gregoire': 1,\n",
       "  '22.58': 0,\n",
       "  '10.': 0,\n",
       "  'troy': 1,\n",
       "  'benson': 1,\n",
       "  '22.56': 0,\n",
       "  'women': 0,\n",
       "  'tatjana': 1,\n",
       "  'mittermayer': 1,\n",
       "  'germany': 1,\n",
       "  '24.32': 0,\n",
       "  'candice': 1,\n",
       "  'gilg': 1,\n",
       "  '24.31': 0,\n",
       "  'minna': 1,\n",
       "  'karhu': 1,\n",
       "  'finland': 1,\n",
       "  '24.05': 0,\n",
       "  'tae': 1,\n",
       "  'satoya': 1,\n",
       "  '23.75': 0,\n",
       "  'ann': 1,\n",
       "  'battellle': 1,\n",
       "  '23.56': 0,\n",
       "  'donna': 1,\n",
       "  'weinbrecht': 1,\n",
       "  '22.48': 0,\n",
       "  'liz': 1,\n",
       "  'mcintyre': 1,\n",
       "  '22.00': 0,\n",
       "  'elena': 1,\n",
       "  'koroleva': 1,\n",
       "  '21.77': 0,\n",
       "  'ljudmila': 1,\n",
       "  'dymchenko': 1,\n",
       "  '21.59': 0,\n",
       "  'katleen': 1,\n",
       "  'allais': 1,\n",
       "  '21.58': 0,\n",
       "  '1': 0,\n",
       "  'halftime': 0,\n",
       "  '0-1': 0,\n",
       "  'scorers': 0,\n",
       "  '84': 0,\n",
       "  '88': 0,\n",
       "  'attendance': 0,\n",
       "  '10,000': 0,\n",
       "  '0': 0,\n",
       "  '0-0': 0,\n",
       "  '78': 0,\n",
       "  'shatskikh': 1,\n",
       "  '90': 0,\n",
       "  'attendence': 0,\n",
       "  '3,000': 0,\n",
       "  'standings': 0,\n",
       "  'tabulate': 0,\n",
       "  'won': 0,\n",
       "  'drawn': 0,\n",
       "  'lost': 0,\n",
       "  'cricket': 0,\n",
       "  'pakistan': 1,\n",
       "  'v': 0,\n",
       "  'new': 0,\n",
       "  'zealand': 1,\n",
       "  'one-day': 0,\n",
       "  'scoreboard': 0,\n",
       "  '[': 0,\n",
       "  'corrected': 0,\n",
       "  '14:06': 0,\n",
       "  'gmt': 1,\n",
       "  ']': 0,\n",
       "  'sialkot': 1,\n",
       "  'international': 0,\n",
       "  'between': 0,\n",
       "  'saeed': 1,\n",
       "  'anwar': 1,\n",
       "  'run': 0,\n",
       "  '91': 0,\n",
       "  'corrects': 0,\n",
       "  'zahoor': 1,\n",
       "  'elahi': 1,\n",
       "  'b': 0,\n",
       "  'cairns': 1,\n",
       "  '86': 0,\n",
       "  '87': 0,\n",
       "  'ijaz': 1,\n",
       "  'ahmad': 1,\n",
       "  'spearman': 1,\n",
       "  'vaughan': 1,\n",
       "  '59': 0,\n",
       "  'inzamamul': 1,\n",
       "  'haq': 1,\n",
       "  'st': 0,\n",
       "  'germon': 1,\n",
       "  'astle': 1,\n",
       "  'wasim': 1,\n",
       "  'akram': 1,\n",
       "  'harris': 1,\n",
       "  'shahid': 1,\n",
       "  'afridi': 1,\n",
       "  'moin': 1,\n",
       "  'khan': 1,\n",
       "  'waqar': 1,\n",
       "  'younis': 1,\n",
       "  'saqlain': 1,\n",
       "  'mushtaq': 1,\n",
       "  'not': 0,\n",
       "  'salim': 1,\n",
       "  'malik': 1,\n",
       "  'extras': 0,\n",
       "  'lb-8': 0,\n",
       "  'nb-2': 0,\n",
       "  'w-14': 0,\n",
       "  'total': 0,\n",
       "  'wickets': 0,\n",
       "  '47': 0,\n",
       "  'overs': 0,\n",
       "  '277': 0,\n",
       "  'fall': 0,\n",
       "  'wicket': 0,\n",
       "  '1-177': 0,\n",
       "  '1-178': 0,\n",
       "  '2-225': 0,\n",
       "  '3-240': 0,\n",
       "  '4-247': 0,\n",
       "  '5-252': 0,\n",
       "  '6-260': 0,\n",
       "  '7-261': 0,\n",
       "  '8-269': 0,\n",
       "  '9-276': 0,\n",
       "  'bowling': 0,\n",
       "  'doull': 1,\n",
       "  '8-1-60-0': 0,\n",
       "  'w-3': 0,\n",
       "  'kennedy': 1,\n",
       "  '3-0-24-0': 0,\n",
       "  'w-7': 0,\n",
       "  'nb-1': 0,\n",
       "  '8-1-35-1': 0,\n",
       "  'w-2': 0,\n",
       "  '9-1-55-1': 0,\n",
       "  '10-0-42-5': 0,\n",
       "  'w-1': 0,\n",
       "  '9-0-53-1': 0,\n",
       "  'innings': 0,\n",
       "  'b.': 1,\n",
       "  'young': 0,\n",
       "  'c.': 1,\n",
       "  'a.': 1,\n",
       "  'parore': 1,\n",
       "  '37': 0,\n",
       "  's.': 1,\n",
       "  'fleming': 1,\n",
       "  'n.': 1,\n",
       "  '20': 0,\n",
       "  'lbw': 0,\n",
       "  '22': 0,\n",
       "  'l.': 1,\n",
       "  'j.': 1,\n",
       "  'subs': 0,\n",
       "  'm.': 1,\n",
       "  'r.': 1,\n",
       "  'b-9': 0,\n",
       "  'lb-3': 0,\n",
       "  'w-12': 0,\n",
       "  '26': 0,\n",
       "  '42.1': 0,\n",
       "  '231': 0,\n",
       "  '1-3': 0,\n",
       "  '2-7': 0,\n",
       "  '3-125': 0,\n",
       "  '4-146': 0,\n",
       "  '5-170': 0,\n",
       "  '6-190': 0,\n",
       "  '7-195': 0,\n",
       "  '8-213': 0,\n",
       "  '9-216': 0,\n",
       "  '8.1-0-43-3': 0,\n",
       "  '9w': 0,\n",
       "  '1nb': 0,\n",
       "  '6-0-32-2': 0,\n",
       "  '2w': 0,\n",
       "  '8-0-54-2': 0,\n",
       "  '10-0-42-0': 0,\n",
       "  '1w': 0,\n",
       "  '7-0-40-2': 0,\n",
       "  '2.5-0-8-1': 0,\n",
       "  '0.1-0-0-0': 0,\n",
       "  'result': 0,\n",
       "  'runs': 0,\n",
       "  'third': 0,\n",
       "  'december': 0,\n",
       "  'karachi': 1,\n",
       "  'english': 1,\n",
       "  'f.a.': 1,\n",
       "  'round': 0,\n",
       "  'london': 1,\n",
       "  'challenge': 1,\n",
       "  'plymouth': 1,\n",
       "  'exeter': 1,\n",
       "  'blinker': 1,\n",
       "  'ban': 0,\n",
       "  'lifted': 0,\n",
       "  'dutch': 1,\n",
       "  'forward': 0,\n",
       "  'reggie': 1,\n",
       "  'indefinite': 0,\n",
       "  'suspension': 0,\n",
       "  'set': 0,\n",
       "  'make': 0,\n",
       "  'sheffield': 1,\n",
       "  'wednesday': 0,\n",
       "  'liverpool': 1,\n",
       "  'club': 0,\n",
       "  'slapped': 0,\n",
       "  'worldwide': 0,\n",
       "  'appearing': 0,\n",
       "  'sign': 0,\n",
       "  'contracts': 0,\n",
       "  'both': 0,\n",
       "  'udinese': 1,\n",
       "  'while': 0,\n",
       "  'feyenoord': 1,\n",
       "  'players': 0,\n",
       "  'status': 0,\n",
       "  'committee': 0,\n",
       "  'barcelona': 1,\n",
       "  'decided': 0,\n",
       "  'although': 0,\n",
       "  'document': 0,\n",
       "  'basically': 0,\n",
       "  'valid': 0,\n",
       "  'could': 0,\n",
       "  'legally': 0,\n",
       "  'protected': 0,\n",
       "  'italian': 1,\n",
       "  'violated': 0,\n",
       "  'regulations': 0,\n",
       "  'failing': 0,\n",
       "  'inform': 0,\n",
       "  'whom': 0,\n",
       "  'contract': 0,\n",
       "  'fined': 0,\n",
       "  '75,000': 0,\n",
       "  'swiss': 1,\n",
       "  'francs': 0,\n",
       "  '$': 0,\n",
       "  '57,600': 0,\n",
       "  'engllsh': 1,\n",
       "  'previous': 0,\n",
       "  'commitment': 0,\n",
       "  'leeds': 1,\n",
       "  'bowyer': 1,\n",
       "  'part': 0,\n",
       "  'fast-food': 0,\n",
       "  'fracas': 0,\n",
       "  'under-21': 0,\n",
       "  'lee': 1,\n",
       "  '4,500': 0,\n",
       "  'pounds': 0,\n",
       "  '7,400': 0,\n",
       "  'hurling': 0,\n",
       "  'chairs': 0,\n",
       "  'restaurant': 0,\n",
       "  'staff': 0,\n",
       "  'during': 0,\n",
       "  'disturbance': 0,\n",
       "  'mcdonald': 1,\n",
       "  'caught': 0,\n",
       "  'act': 0,\n",
       "  'security': 0,\n",
       "  'cameras': 0,\n",
       "  'pleaded': 0,\n",
       "  'guilty': 0,\n",
       "  'charge': 0,\n",
       "  'affray': 0,\n",
       "  'court': 0,\n",
       "  'ordered': 0,\n",
       "  'pay': 0,\n",
       "  '175': 0,\n",
       "  'members': 0,\n",
       "  'injured': 0,\n",
       "  'east': 0,\n",
       "  'october': 0,\n",
       "  'already': 0,\n",
       "  '4,000': 0,\n",
       "  '6,600': 0,\n",
       "  'warned': 0,\n",
       "  'repeat': 0,\n",
       "  'criminal': 0,\n",
       "  'behaviour': 0,\n",
       "  'cost': 0,\n",
       "  'place': 0,\n",
       "  'moved': 0,\n",
       "  'yorkshire': 1,\n",
       "  'august': 0,\n",
       "  '3.5': 0,\n",
       "  'million': 0,\n",
       "  '5.8': 0,\n",
       "  'expected': 0,\n",
       "  'middlesbrough': 1,\n",
       "  'basketball': 0,\n",
       "  'euroleague': 1,\n",
       "  'thursday': 0,\n",
       "  'cska': 1,\n",
       "  'moscow': 1,\n",
       "  'stefanel': 1,\n",
       "  'milan': 1,\n",
       "  'maccabi': 1,\n",
       "  'tel': 1,\n",
       "  'aviv': 1,\n",
       "  'israel': 1,\n",
       "  'ulker': 1,\n",
       "  'spor': 1,\n",
       "  'turkey': 1,\n",
       "  'limoges': 1,\n",
       "  'panionios': 1,\n",
       "  'greece': 1,\n",
       "  'teamsystem': 1,\n",
       "  'bologna': 1,\n",
       "  'olympiakos': 1,\n",
       "  'cibona': 1,\n",
       "  'zagreb': 1,\n",
       "  'croatia': 1,\n",
       "  'alba': 1,\n",
       "  'berlin': 1,\n",
       "  'estudiantes': 1,\n",
       "  'madrid': 1,\n",
       "  'spain': 1,\n",
       "  'charleroi': 1,\n",
       "  'belgium': 1,\n",
       "  'panathinaikos': 1,\n",
       "  'ljubljana': 1,\n",
       "  'slovenia': 1,\n",
       "  'villeurbanne': 1,\n",
       "  'split': 0,\n",
       "  'bayer': 1,\n",
       "  'leverkusen': 1,\n",
       "  'd': 0,\n",
       "  'efes': 1,\n",
       "  'pilsen': 1,\n",
       "  'pau-orthez': 1,\n",
       "  'partizan': 1,\n",
       "  'belgrade': 1,\n",
       "  'yugoslavia': 1,\n",
       "  'kinder': 0,\n",
       "  'sevilla': 1,\n",
       "  'dynamo': 1,\n",
       "  'little': 0,\n",
       "  'miss': 0,\n",
       "  'campese': 1,\n",
       "  'farewell': 0,\n",
       "  'robert': 1,\n",
       "  'kitson': 1,\n",
       "  'centre': 0,\n",
       "  'jason': 1,\n",
       "  'will': 0,\n",
       "  'australia': 1,\n",
       "  'end-of-tour': 0,\n",
       "  'fixture': 0,\n",
       "  'barbarians': 1,\n",
       "  'has': 0,\n",
       "  'opted': 0,\n",
       "  'risk': 0,\n",
       "  'aggravating': 0,\n",
       "  'knee': 0,\n",
       "  'ruled': 0,\n",
       "  'large': 0,\n",
       "  'chunk': 0,\n",
       "  'tour': 0,\n",
       "  'replaced': 0,\n",
       "  'fellow': 0,\n",
       "  'queenslander': 1,\n",
       "  'daniel': 1,\n",
       "  'herbert': 1,\n",
       "  'owen': 1,\n",
       "  'finegan': 1,\n",
       "  'recovered': 0,\n",
       "  'knocks': 0,\n",
       "  'weekend': 0,\n",
       "  'test': 0,\n",
       "  'wales': 1,\n",
       "  'retains': 0,\n",
       "  'back-row': 0,\n",
       "  'ahead': 0,\n",
       "  'manu': 1,\n",
       "  'wallabies': 1,\n",
       "  'sights': 0,\n",
       "  '13th': 0,\n",
       "  'successive': 0,\n",
       "  'end': 0,\n",
       "  'european': 1,\n",
       "  '100': 0,\n",
       "  'percent': 0,\n",
       "  'record': 0,\n",
       "  'also': 0,\n",
       "  'want': 0,\n",
       "  'turn': 0,\n",
       "  'style': 0,\n",
       "  'provide': 0,\n",
       "  'david': 1,\n",
       "  'fitting': 0,\n",
       "  'send-off': 0,\n",
       "  'final': 0,\n",
       "  'australian': 0,\n",
       "  'colours': 0,\n",
       "  'currently': 0,\n",
       "  'no': 0,\n",
       "  'plans': 0,\n",
       "  'any': 0,\n",
       "  'special': 0,\n",
       "  'presentation': 0,\n",
       "  '34-year-old': 0,\n",
       "  'winger': 0,\n",
       "  'full': 0,\n",
       "  'house': 0,\n",
       "  'spectators': 0,\n",
       "  'still': 0,\n",
       "  'gather': 0,\n",
       "  'hope': 0,\n",
       "  'witnessing': 0,\n",
       "  'moment': 0,\n",
       "  'magic': 0,\n",
       "  'up': 0,\n",
       "  'familiar': 0,\n",
       "  'foe': 0,\n",
       "  'shape': 0,\n",
       "  'captain': 0,\n",
       "  'rob': 0,\n",
       "  'andrew': 1,\n",
       "  'man': 0,\n",
       "  'kicked': 0,\n",
       "  'last-ditch': 0,\n",
       "  'drop-goal': 0,\n",
       "  'quarter-final': 0,\n",
       "  'cape': 1,\n",
       "  'town': 0,\n",
       "  'campo': 1,\n",
       "  'massive': 0,\n",
       "  'this': 0,\n",
       "  'country': 0,\n",
       "  'public': 0,\n",
       "  'ever': 0,\n",
       "  'since': 0,\n",
       "  '1984': 0,\n",
       "  'likely': 0,\n",
       "  'making': 0,\n",
       "  'appearance': 0,\n",
       "  'tests': 0,\n",
       "  'ireland': 1,\n",
       "  '414': 0,\n",
       "  'average': 0,\n",
       "  'almost': 0,\n",
       "  '35': 0,\n",
       "  'league': 0,\n",
       "  'duties': 0,\n",
       "  'restricted': 0,\n",
       "  'selectorial': 0,\n",
       "  'options': 0,\n",
       "  'boast': 0,\n",
       "  'internationals': 0,\n",
       "  'including': 0,\n",
       "  'full-back': 0,\n",
       "  'tim': 1,\n",
       "  'stimpson': 1,\n",
       "  'tony': 1,\n",
       "  'underwood': 1,\n",
       "  'plus': 0,\n",
       "  'black': 1,\n",
       "  'forwards': 0,\n",
       "  'ian': 1,\n",
       "  'jones': 1,\n",
       "  'norm': 1,\n",
       "  'hewitt': 1,\n",
       "  'nigel': 1,\n",
       "  'walker': 1,\n",
       "  'allan': 1,\n",
       "  'bateman': 1,\n",
       "  'gregor': 1,\n",
       "  'townsend': 1,\n",
       "  'howley': 1,\n",
       "  'scott': 1,\n",
       "  'quinnell': 1,\n",
       "  'neil': 1,\n",
       "  'dale': 1,\n",
       "  'mcintosh': 1,\n",
       "  'pontypridd': 1,\n",
       "  'craig': 1,\n",
       "  'darren': 1,\n",
       "  'garforth': 1,\n",
       "  'leicester': 1,\n",
       "  'nick': 1,\n",
       "  'popplewell': 1,\n",
       "  'matthew': 1,\n",
       "  'burke': 1,\n",
       "  'joe': 1,\n",
       "  ...})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dict, main_dict_valid, main_dict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_dataset(Dataset):\n",
    "    def __init__(self,train_dict,wvs):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.count = 0\n",
    "        self.train_dict = train_dict\n",
    "        self.wvs = wvs\n",
    "        self.keys = list(self.train_dict.keys())\n",
    "        for i,x in enumerate(self.train_dict):\n",
    "            try:\n",
    "                self.wvs.wv[self.keys[i]]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                self.wvs.wv[self.keys[i+1]]\n",
    "            except:\n",
    "                continue                                                                                \n",
    "                \n",
    "            try:\n",
    "                self.wvs.wv[self.keys[i+2]]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            if self.count==0:\n",
    "                self.x_cat_sub = torch.cat((torch.tensor(self.wvs.wv[self.keys[i]]),torch.tensor(self.wvs.wv[self.keys[i+1]])),0)\n",
    "                self.x_cat_sub = torch.cat((self.x_cat_sub,torch.tensor(self.wvs.wv[self.keys[i+2]])),0)\n",
    "                self.X_train = torch.unsqueeze(self.x_cat_sub,0)\n",
    "                self.Y_train = torch.unsqueeze(torch.tensor(self.train_dict[self.keys[i+1]]),0)\n",
    "                self.count=self.count+1\n",
    "                \n",
    "            else:\n",
    "                self.x_cat_sub = torch.cat((torch.tensor(self.wvs.wv[self.keys[i]]),torch.tensor(self.wvs.wv[self.keys[i+1]])),0)\n",
    "                self.x_cat_sub = torch.cat((self.x_cat_sub,torch.tensor(self.wvs.wv[self.keys[i+2]])),0)\n",
    "                self.x_cat_sub = torch.unsqueeze(self.x_cat_sub,0)\n",
    "                \n",
    "                self.temp_tensor_y = torch.unsqueeze(torch.tensor(self.train_dict[x]),0)\n",
    "                \n",
    "                self.X_train = torch.cat((self.X_train,self.x_cat_sub),0)\n",
    "                self.Y_train = torch.cat((self.Y_train,self.temp_tensor_y),0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X_train.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.Y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binary_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Binary_classifier, self).__init__()\n",
    "        self.fci = nn.Linear(300,100)\n",
    "        self.fc1 = nn.Linear(100,50)\n",
    "        self.fc2 = nn.Linear(50,2)\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "                \n",
    "    def forward(self,x):\n",
    "        x = self.fci(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Named_Entity_Recognition(train, valid, save_file, num_of_epochs = 100):\n",
    "\n",
    "    model = Binary_classifier()\n",
    "    temp_tensor = torch.randn(64,300)\n",
    "    model(temp_tensor).shape\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.000001) \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)    \n",
    "\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))    \n",
    "\n",
    "    print(summary(model,(1,300)))\n",
    "    \n",
    "    min_valid_loss = np.inf\n",
    "    \n",
    "    for e in range(num_of_epochs):\n",
    "\n",
    "        train_loss = 0.0\n",
    "        for data, labels in train:\n",
    "            # Transfer Data to GPU if available\n",
    "    #         if torch.cuda.is_available():\n",
    "    #             data, labels = data.cuda(), labels.cuda()\n",
    "            \n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward Pass\n",
    "            target = model(data)\n",
    "            # Find the Loss\n",
    "            loss = criterion(target,labels)\n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "            # Update Weights\n",
    "            optimizer.step()\n",
    "            # Calculate Loss\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        model.eval()     # Optional when not using Model Specific layer\n",
    "        \n",
    "        for data, labels in valid:\n",
    "            # Transfer Data to GPU if available\n",
    "    #         if torch.cuda.is_available():\n",
    "    #             data, labels = data.cuda(), labels.cuda()\n",
    "            \n",
    "            # Forward Pass\n",
    "            target = model(data)\n",
    "            # Find the Loss\n",
    "            loss = criterion(target,labels)\n",
    "            # Calculate Loss\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "        print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train)} \\t\\t Validation Loss: { valid_loss / len(valid)}')\n",
    "        \n",
    "        if min_valid_loss > valid_loss:\n",
    "            print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "            min_valid_loss = valid_loss\n",
    "            \n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), save_file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test, save_file):\n",
    "    \n",
    "    model = Binary_classifier()\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    model.eval()\n",
    "\n",
    "    cf_mat = np.zeros((2,2))\n",
    "    for x, y in test:\n",
    "        output = model(x)\n",
    "        output_arr = np.asarray(output.detach())\n",
    "        fin = np.argmax(output_arr, axis=None)\n",
    "        cf_mat[y][fin] += 1\n",
    "\n",
    "    print(\"Results of the model are:\")\n",
    "    print(cf_mat)\n",
    "    \n",
    "    # Calculating Accuracy\n",
    "    accuracy = (cf_mat[0][0] + cf_mat[1][1])/(cf_mat[0][0] + cf_mat[0][1] + cf_mat[1][0] + cf_mat[1][1])\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "    # Calculating Precision\n",
    "    precision = cf_mat[0][0]/(cf_mat[0][0] + cf_mat[0][1])\n",
    "    print(\"Precision: {}\".format(precision))\n",
    "\n",
    "    # Calculating Recall\n",
    "\n",
    "    recall = cf_mat[0][0]/(cf_mat[0][0] + cf_mat[1][0])\n",
    "    print(\"Recall: {}\".format(recall))\n",
    "\n",
    "    # Calculating F1 Score\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    print(\"F1 Score: {}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW with Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = Word2Vec.load(r'cbow_with_negative_model')\n",
    "train = DataLoader(load_dataset(main_dict,word_embedding), batch_size=64)\n",
    "valid = DataLoader(load_dataset(main_dict_valid,word_embedding), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: \n",
      "35252\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]          30,100\n",
      "           Sigmoid-2               [-1, 1, 100]               0\n",
      "            Linear-3                [-1, 1, 50]           5,050\n",
      "           Sigmoid-4                [-1, 1, 50]               0\n",
      "            Linear-5                 [-1, 1, 2]             102\n",
      "           Sigmoid-6                 [-1, 1, 2]               0\n",
      "================================================================\n",
      "Total params: 35,252\n",
      "Trainable params: 35,252\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.14\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Epoch 1 \t\t Training Loss: 0.6671067841418155 \t\t Validation Loss: 0.6664536790769608\n",
      "Validation Loss Decreased(inf--->40.653674) \t Saving The Model\n",
      "Epoch 2 \t\t Training Loss: 0.6656387534227457 \t\t Validation Loss: 0.6649923617722558\n",
      "Validation Loss Decreased(40.653674--->40.564534) \t Saving The Model\n",
      "Epoch 3 \t\t Training Loss: 0.664174290390702 \t\t Validation Loss: 0.6635345347592088\n",
      "Validation Loss Decreased(40.564534--->40.475607) \t Saving The Model\n",
      "Epoch 4 \t\t Training Loss: 0.6627132855020128 \t\t Validation Loss: 0.6620803827145061\n",
      "Validation Loss Decreased(40.475607--->40.386903) \t Saving The Model\n",
      "Epoch 5 \t\t Training Loss: 0.6612559079049943 \t\t Validation Loss: 0.6606299232264035\n",
      "Validation Loss Decreased(40.386903--->40.298425) \t Saving The Model\n",
      "Epoch 6 \t\t Training Loss: 0.6598021538407953 \t\t Validation Loss: 0.659183078124875\n",
      "Validation Loss Decreased(40.298425--->40.210168) \t Saving The Model\n",
      "Epoch 7 \t\t Training Loss: 0.6583520324380548 \t\t Validation Loss: 0.6577398405700433\n",
      "Validation Loss Decreased(40.210168--->40.122130) \t Saving The Model\n",
      "Epoch 8 \t\t Training Loss: 0.6569054959056614 \t\t Validation Loss: 0.6563002066534074\n",
      "Validation Loss Decreased(40.122130--->40.034313) \t Saving The Model\n",
      "Epoch 9 \t\t Training Loss: 0.6554625727034904 \t\t Validation Loss: 0.6548642115514787\n",
      "Validation Loss Decreased(40.034313--->39.946717) \t Saving The Model\n",
      "Epoch 10 \t\t Training Loss: 0.6540233213622291 \t\t Validation Loss: 0.6534319099832754\n",
      "Validation Loss Decreased(39.946717--->39.859347) \t Saving The Model\n",
      "Epoch 11 \t\t Training Loss: 0.6525877547693683 \t\t Validation Loss: 0.6520032560239073\n",
      "Validation Loss Decreased(39.859347--->39.772199) \t Saving The Model\n",
      "Epoch 12 \t\t Training Loss: 0.6511558697030351 \t\t Validation Loss: 0.650578323934899\n",
      "Validation Loss Decreased(39.772199--->39.685278) \t Saving The Model\n",
      "Epoch 13 \t\t Training Loss: 0.6497276763658266 \t\t Validation Loss: 0.6491570892881174\n",
      "Validation Loss Decreased(39.685278--->39.598582) \t Saving The Model\n",
      "Epoch 14 \t\t Training Loss: 0.6483032236228118 \t\t Validation Loss: 0.6477396292764632\n",
      "Validation Loss Decreased(39.598582--->39.512117) \t Saving The Model\n",
      "Epoch 15 \t\t Training Loss: 0.6468825399338662 \t\t Validation Loss: 0.6463259194718033\n",
      "Validation Loss Decreased(39.512117--->39.425881) \t Saving The Model\n",
      "Epoch 16 \t\t Training Loss: 0.6454656510739714 \t\t Validation Loss: 0.6449160048219024\n",
      "Validation Loss Decreased(39.425881--->39.339876) \t Saving The Model\n",
      "Epoch 17 \t\t Training Loss: 0.6440525559691695 \t\t Validation Loss: 0.6435099048692672\n",
      "Validation Loss Decreased(39.339876--->39.254104) \t Saving The Model\n",
      "Epoch 18 \t\t Training Loss: 0.6426432744876759 \t\t Validation Loss: 0.6421076059341431\n",
      "Validation Loss Decreased(39.254104--->39.168564) \t Saving The Model\n",
      "Epoch 19 \t\t Training Loss: 0.6412378270346839 \t\t Validation Loss: 0.6407091598041722\n",
      "Validation Loss Decreased(39.168564--->39.083259) \t Saving The Model\n",
      "Epoch 20 \t\t Training Loss: 0.6398362383112177 \t\t Validation Loss: 0.6393145723421065\n",
      "Validation Loss Decreased(39.083259--->38.998189) \t Saving The Model\n",
      "Epoch 21 \t\t Training Loss: 0.6384385126131075 \t\t Validation Loss: 0.6379238816558338\n",
      "Validation Loss Decreased(38.998189--->38.913357) \t Saving The Model\n",
      "Epoch 22 \t\t Training Loss: 0.6370446971944861 \t\t Validation Loss: 0.6365370906767298\n",
      "Validation Loss Decreased(38.913357--->38.828763) \t Saving The Model\n",
      "Epoch 23 \t\t Training Loss: 0.6356547947402473 \t\t Validation Loss: 0.6351541867021655\n",
      "Validation Loss Decreased(38.828763--->38.744405) \t Saving The Model\n",
      "Epoch 24 \t\t Training Loss: 0.6342688127680942 \t\t Validation Loss: 0.6337752420394147\n",
      "Validation Loss Decreased(38.744405--->38.660290) \t Saving The Model\n",
      "Epoch 25 \t\t Training Loss: 0.6328867716832204 \t\t Validation Loss: 0.6324002136949634\n",
      "Validation Loss Decreased(38.660290--->38.576413) \t Saving The Model\n",
      "Epoch 26 \t\t Training Loss: 0.6315086730965623 \t\t Validation Loss: 0.6310291671362079\n",
      "Validation Loss Decreased(38.576413--->38.492779) \t Saving The Model\n",
      "Epoch 27 \t\t Training Loss: 0.6301345508377831 \t\t Validation Loss: 0.6296620779350156\n",
      "Validation Loss Decreased(38.492779--->38.409387) \t Saving The Model\n",
      "Epoch 28 \t\t Training Loss: 0.6287644376625886 \t\t Validation Loss: 0.628298999833279\n",
      "Validation Loss Decreased(38.409387--->38.326239) \t Saving The Model\n",
      "Epoch 29 \t\t Training Loss: 0.6273983185355728 \t\t Validation Loss: 0.6269399416251261\n",
      "Validation Loss Decreased(38.326239--->38.243336) \t Saving The Model\n",
      "Epoch 30 \t\t Training Loss: 0.6260362546723168 \t\t Validation Loss: 0.6255849267615646\n",
      "Validation Loss Decreased(38.243336--->38.160681) \t Saving The Model\n",
      "Epoch 31 \t\t Training Loss: 0.6246782401660541 \t\t Validation Loss: 0.6242339630595973\n",
      "Validation Loss Decreased(38.160681--->38.078272) \t Saving The Model\n",
      "Epoch 32 \t\t Training Loss: 0.6233243024027025 \t\t Validation Loss: 0.622887095466989\n",
      "Validation Loss Decreased(38.078272--->37.996113) \t Saving The Model\n",
      "Epoch 33 \t\t Training Loss: 0.6219744682312012 \t\t Validation Loss: 0.621544349388998\n",
      "Validation Loss Decreased(37.996113--->37.914205) \t Saving The Model\n",
      "Epoch 34 \t\t Training Loss: 0.6206287553718498 \t\t Validation Loss: 0.6202056896491129\n",
      "Validation Loss Decreased(37.914205--->37.832547) \t Saving The Model\n",
      "Epoch 35 \t\t Training Loss: 0.6192871584548606 \t\t Validation Loss: 0.6188711690121009\n",
      "Validation Loss Decreased(37.832547--->37.751141) \t Saving The Model\n",
      "Epoch 36 \t\t Training Loss: 0.6179497241973877 \t\t Validation Loss: 0.6175408128832207\n",
      "Validation Loss Decreased(37.751141--->37.669990) \t Saving The Model\n",
      "Epoch 37 \t\t Training Loss: 0.6166164542103673 \t\t Validation Loss: 0.6162146339651013\n",
      "Validation Loss Decreased(37.669990--->37.589093) \t Saving The Model\n",
      "Epoch 38 \t\t Training Loss: 0.6152873764166961 \t\t Validation Loss: 0.6148926283492416\n",
      "Validation Loss Decreased(37.589093--->37.508450) \t Saving The Model\n",
      "Epoch 39 \t\t Training Loss: 0.6139624881314801 \t\t Validation Loss: 0.6135748390291558\n",
      "Validation Loss Decreased(37.508450--->37.428065) \t Saving The Model\n",
      "Epoch 40 \t\t Training Loss: 0.6126418387567675 \t\t Validation Loss: 0.6122612738218464\n",
      "Validation Loss Decreased(37.428065--->37.347938) \t Saving The Model\n",
      "Epoch 41 \t\t Training Loss: 0.6113254336623458 \t\t Validation Loss: 0.6109519679038251\n",
      "Validation Loss Decreased(37.347938--->37.268070) \t Saving The Model\n",
      "Epoch 42 \t\t Training Loss: 0.610013283050812 \t\t Validation Loss: 0.6096469144352147\n",
      "Validation Loss Decreased(37.268070--->37.188462) \t Saving The Model\n",
      "Epoch 43 \t\t Training Loss: 0.6087054186039143 \t\t Validation Loss: 0.6083461505467774\n",
      "Validation Loss Decreased(37.188462--->37.109115) \t Saving The Model\n",
      "Epoch 44 \t\t Training Loss: 0.6074018494502919 \t\t Validation Loss: 0.6070496908953933\n",
      "Validation Loss Decreased(37.109115--->37.030031) \t Saving The Model\n",
      "Epoch 45 \t\t Training Loss: 0.606102606734714 \t\t Validation Loss: 0.6057575726118244\n",
      "Validation Loss Decreased(37.030031--->36.951212) \t Saving The Model\n",
      "Epoch 46 \t\t Training Loss: 0.6048077232128864 \t\t Validation Loss: 0.6044697878790684\n",
      "Validation Loss Decreased(36.951212--->36.872657) \t Saving The Model\n",
      "Epoch 47 \t\t Training Loss: 0.6035171838494034 \t\t Validation Loss: 0.6031863630795088\n",
      "Validation Loss Decreased(36.872657--->36.794368) \t Saving The Model\n",
      "Epoch 48 \t\t Training Loss: 0.6022310267697584 \t\t Validation Loss: 0.6019073167785269\n",
      "Validation Loss Decreased(36.794368--->36.716346) \t Saving The Model\n",
      "Epoch 49 \t\t Training Loss: 0.6009492589546753 \t\t Validation Loss: 0.6006326665643786\n",
      "Validation Loss Decreased(36.716346--->36.638593) \t Saving The Model\n",
      "Epoch 50 \t\t Training Loss: 0.5996719094010087 \t\t Validation Loss: 0.5993624378423221\n",
      "Validation Loss Decreased(36.638593--->36.561109) \t Saving The Model\n",
      "Epoch 51 \t\t Training Loss: 0.5983989899222916 \t\t Validation Loss: 0.5980966462463629\n",
      "Validation Loss Decreased(36.561109--->36.483895) \t Saving The Model\n",
      "Epoch 52 \t\t Training Loss: 0.5971305354221447 \t\t Validation Loss: 0.5968353337928897\n",
      "Validation Loss Decreased(36.483895--->36.406955) \t Saving The Model\n",
      "Epoch 53 \t\t Training Loss: 0.5958665587880589 \t\t Validation Loss: 0.5955784770308948\n",
      "Validation Loss Decreased(36.406955--->36.330287) \t Saving The Model\n",
      "Epoch 54 \t\t Training Loss: 0.5946070643158646 \t\t Validation Loss: 0.5943261209081431\n",
      "Validation Loss Decreased(36.330287--->36.253893) \t Saving The Model\n",
      "Epoch 55 \t\t Training Loss: 0.5933520933529278 \t\t Validation Loss: 0.5930782732416372\n",
      "Validation Loss Decreased(36.253893--->36.177775) \t Saving The Model\n",
      "Epoch 56 \t\t Training Loss: 0.5921016356966518 \t\t Validation Loss: 0.5918349535738836\n",
      "Validation Loss Decreased(36.177775--->36.101932) \t Saving The Model\n",
      "Epoch 57 \t\t Training Loss: 0.590855728935551 \t\t Validation Loss: 0.5905961677676341\n",
      "Validation Loss Decreased(36.101932--->36.026366) \t Saving The Model\n",
      "Epoch 58 \t\t Training Loss: 0.5896143639409864 \t\t Validation Loss: 0.5893619285255182\n",
      "Validation Loss Decreased(36.026366--->35.951078) \t Saving The Model\n",
      "Epoch 59 \t\t Training Loss: 0.588377557896279 \t\t Validation Loss: 0.5881322524586662\n",
      "Validation Loss Decreased(35.951078--->35.876067) \t Saving The Model\n",
      "Epoch 60 \t\t Training Loss: 0.5871453376503678 \t\t Validation Loss: 0.5869071337043262\n",
      "Validation Loss Decreased(35.876067--->35.801335) \t Saving The Model\n",
      "Epoch 61 \t\t Training Loss: 0.5859177139428284 \t\t Validation Loss: 0.5856866387070202\n",
      "Validation Loss Decreased(35.801335--->35.726885) \t Saving The Model\n",
      "Epoch 62 \t\t Training Loss: 0.5846946964392791 \t\t Validation Loss: 0.5844707606268711\n",
      "Validation Loss Decreased(35.726885--->35.652716) \t Saving The Model\n",
      "Epoch 63 \t\t Training Loss: 0.5834763205803193 \t\t Validation Loss: 0.58325950337238\n",
      "Validation Loss Decreased(35.652716--->35.578830) \t Saving The Model\n",
      "Epoch 64 \t\t Training Loss: 0.5822625815331399 \t\t Validation Loss: 0.5820528825775522\n",
      "Validation Loss Decreased(35.578830--->35.505226) \t Saving The Model\n",
      "Epoch 65 \t\t Training Loss: 0.5810535222560436 \t\t Validation Loss: 0.5808509510071551\n",
      "Validation Loss Decreased(35.505226--->35.431908) \t Saving The Model\n",
      "Epoch 66 \t\t Training Loss: 0.5798491330834122 \t\t Validation Loss: 0.5796536773931785\n",
      "Validation Loss Decreased(35.431908--->35.358874) \t Saving The Model\n",
      "Epoch 67 \t\t Training Loss: 0.5786494252918003 \t\t Validation Loss: 0.5784610959350086\n",
      "Validation Loss Decreased(35.358874--->35.286127) \t Saving The Model\n",
      "Epoch 68 \t\t Training Loss: 0.5774544262671256 \t\t Validation Loss: 0.5772732056555201\n",
      "Validation Loss Decreased(35.286127--->35.213666) \t Saving The Model\n",
      "Epoch 69 \t\t Training Loss: 0.5762641247328337 \t\t Validation Loss: 0.5760900016690864\n",
      "Validation Loss Decreased(35.213666--->35.141490) \t Saving The Model\n",
      "Epoch 70 \t\t Training Loss: 0.5750785292805852 \t\t Validation Loss: 0.5749115054724646\n",
      "Validation Loss Decreased(35.141490--->35.069602) \t Saving The Model\n",
      "Epoch 71 \t\t Training Loss: 0.5738976630004676 \t\t Validation Loss: 0.5737377405166626\n",
      "Validation Loss Decreased(35.069602--->34.998002) \t Saving The Model\n",
      "Epoch 72 \t\t Training Loss: 0.5727215500565263 \t\t Validation Loss: 0.5725687214585601\n",
      "Validation Loss Decreased(34.998002--->34.926692) \t Saving The Model\n",
      "Epoch 73 \t\t Training Loss: 0.5715501925966762 \t\t Validation Loss: 0.5714044600236611\n",
      "Validation Loss Decreased(34.926692--->34.855672) \t Saving The Model\n",
      "Epoch 74 \t\t Training Loss: 0.5703835927688323 \t\t Validation Loss: 0.570244957189091\n",
      "Validation Loss Decreased(34.855672--->34.784942) \t Saving The Model\n",
      "Epoch 75 \t\t Training Loss: 0.569221780106828 \t\t Validation Loss: 0.5690902119777241\n",
      "Validation Loss Decreased(34.784942--->34.714503) \t Saving The Model\n",
      "Epoch 76 \t\t Training Loss: 0.5680647551476419 \t\t Validation Loss: 0.5679402703144512\n",
      "Validation Loss Decreased(34.714503--->34.644356) \t Saving The Model\n",
      "Epoch 77 \t\t Training Loss: 0.5669125216501253 \t\t Validation Loss: 0.5667951038626374\n",
      "Validation Loss Decreased(34.644356--->34.574501) \t Saving The Model\n",
      "Epoch 78 \t\t Training Loss: 0.5657650876689602 \t\t Validation Loss: 0.565654739981792\n",
      "Validation Loss Decreased(34.574501--->34.504939) \t Saving The Model\n",
      "Epoch 79 \t\t Training Loss: 0.5646224650176795 \t\t Validation Loss: 0.564519169877787\n",
      "Validation Loss Decreased(34.504939--->34.435669) \t Saving The Model\n",
      "Epoch 80 \t\t Training Loss: 0.5634846488634745 \t\t Validation Loss: 0.5633884140702544\n",
      "Validation Loss Decreased(34.435669--->34.366693) \t Saving The Model\n",
      "Epoch 81 \t\t Training Loss: 0.5623516741099658 \t\t Validation Loss: 0.5622624686506928\n",
      "Validation Loss Decreased(34.366693--->34.298011) \t Saving The Model\n",
      "Epoch 82 \t\t Training Loss: 0.5612235208889386 \t\t Validation Loss: 0.561141351207358\n",
      "Validation Loss Decreased(34.298011--->34.229622) \t Saving The Model\n",
      "Epoch 83 \t\t Training Loss: 0.5601002090686077 \t\t Validation Loss: 0.560025080305631\n",
      "Validation Loss Decreased(34.229622--->34.161530) \t Saving The Model\n",
      "Epoch 84 \t\t Training Loss: 0.5589817434817821 \t\t Validation Loss: 0.5589136158833738\n",
      "Validation Loss Decreased(34.161530--->34.093731) \t Saving The Model\n",
      "Epoch 85 \t\t Training Loss: 0.5578681209065892 \t\t Validation Loss: 0.5578070116824791\n",
      "Validation Loss Decreased(34.093731--->34.026228) \t Saving The Model\n",
      "Epoch 86 \t\t Training Loss: 0.5567593510086472 \t\t Validation Loss: 0.5567052383891872\n",
      "Validation Loss Decreased(34.026228--->33.959020) \t Saving The Model\n",
      "Epoch 87 \t\t Training Loss: 0.5556554294921257 \t\t Validation Loss: 0.5556083077290019\n",
      "Validation Loss Decreased(33.959020--->33.892107) \t Saving The Model\n",
      "Epoch 88 \t\t Training Loss: 0.5545563730033668 \t\t Validation Loss: 0.5545162372901792\n",
      "Validation Loss Decreased(33.892107--->33.825490) \t Saving The Model\n",
      "Epoch 89 \t\t Training Loss: 0.5534621638220709 \t\t Validation Loss: 0.5534289909190819\n",
      "Validation Loss Decreased(33.825490--->33.759168) \t Saving The Model\n",
      "Epoch 90 \t\t Training Loss: 0.552372821816453 \t\t Validation Loss: 0.5523466155177257\n",
      "Validation Loss Decreased(33.759168--->33.693144) \t Saving The Model\n",
      "Epoch 91 \t\t Training Loss: 0.5512883405427675 \t\t Validation Loss: 0.5512690847037268\n",
      "Validation Loss Decreased(33.693144--->33.627414) \t Saving The Model\n",
      "Epoch 92 \t\t Training Loss: 0.5502087339624628 \t\t Validation Loss: 0.5501964141110904\n",
      "Validation Loss Decreased(33.627414--->33.561981) \t Saving The Model\n",
      "Epoch 93 \t\t Training Loss: 0.5491339967057511 \t\t Validation Loss: 0.5491286037398166\n",
      "Validation Loss Decreased(33.561981--->33.496845) \t Saving The Model\n",
      "Epoch 94 \t\t Training Loss: 0.5480641142742054 \t\t Validation Loss: 0.5480656428415267\n",
      "Validation Loss Decreased(33.496845--->33.432004) \t Saving The Model\n",
      "Epoch 95 \t\t Training Loss: 0.5469991086839555 \t\t Validation Loss: 0.5470075372789727\n",
      "Validation Loss Decreased(33.432004--->33.367460) \t Saving The Model\n",
      "Epoch 96 \t\t Training Loss: 0.5459389810089592 \t\t Validation Loss: 0.5459543183201649\n",
      "Validation Loss Decreased(33.367460--->33.303213) \t Saving The Model\n",
      "Epoch 97 \t\t Training Loss: 0.5448837355450467 \t\t Validation Loss: 0.5449059644683463\n",
      "Validation Loss Decreased(33.303213--->33.239264) \t Saving The Model\n",
      "Epoch 98 \t\t Training Loss: 0.543833372292218 \t\t Validation Loss: 0.543862482563394\n",
      "Validation Loss Decreased(33.239264--->33.175611) \t Saving The Model\n",
      "Epoch 99 \t\t Training Loss: 0.5427879127296241 \t\t Validation Loss: 0.5428238745595588\n",
      "Validation Loss Decreased(33.175611--->33.112256) \t Saving The Model\n",
      "Epoch 100 \t\t Training Loss: 0.5417473122880265 \t\t Validation Loss: 0.5417901209143342\n",
      "Validation Loss Decreased(33.112256--->33.049197) \t Saving The Model\n"
     ]
    }
   ],
   "source": [
    "Named_Entity_Recognition(train, valid, r'cbow_negative.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataLoader(load_dataset(main_dict_test,word_embedding), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the model are:\n",
      "[[3263.    0.]\n",
      " [ 200.    0.]]\n",
      "Accuracy: 0.9422466069881605\n",
      "Precision: 1.0\n",
      "Recall: 0.9422466069881605\n",
      "F1 Score: 0.9702646446625037\n"
     ]
    }
   ],
   "source": [
    "evaluate(test, r'cbow_negative.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKIP GRAM with Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = Word2Vec.load(r'skip_with_negative_model')\n",
    "train = DataLoader(load_dataset(main_dict,word_embedding), batch_size=64)\n",
    "valid = DataLoader(load_dataset(main_dict_valid,word_embedding), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: \n",
      "35252\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]          30,100\n",
      "           Sigmoid-2               [-1, 1, 100]               0\n",
      "            Linear-3                [-1, 1, 50]           5,050\n",
      "           Sigmoid-4                [-1, 1, 50]               0\n",
      "            Linear-5                 [-1, 1, 2]             102\n",
      "           Sigmoid-6                 [-1, 1, 2]               0\n",
      "================================================================\n",
      "Total params: 35,252\n",
      "Trainable params: 35,252\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.14\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Epoch 1 \t\t Training Loss: 0.6544987800958995 \t\t Validation Loss: 0.6539470680424424\n",
      "Validation Loss Decreased(inf--->39.890771) \t Saving The Model\n",
      "Epoch 2 \t\t Training Loss: 0.6531451892208409 \t\t Validation Loss: 0.6526003812180191\n",
      "Validation Loss Decreased(39.890771--->39.808623) \t Saving The Model\n",
      "Epoch 3 \t\t Training Loss: 0.6517962195851781 \t\t Validation Loss: 0.6512582849283688\n",
      "Validation Loss Decreased(39.808623--->39.726755) \t Saving The Model\n",
      "Epoch 4 \t\t Training Loss: 0.6504517546645155 \t\t Validation Loss: 0.6499208690690212\n",
      "Validation Loss Decreased(39.726755--->39.645173) \t Saving The Model\n",
      "Epoch 5 \t\t Training Loss: 0.6491119045395035 \t\t Validation Loss: 0.6485881121432195\n",
      "Validation Loss Decreased(39.645173--->39.563875) \t Saving The Model\n",
      "Epoch 6 \t\t Training Loss: 0.6477767331106169 \t\t Validation Loss: 0.6472599867914544\n",
      "Validation Loss Decreased(39.563875--->39.482859) \t Saving The Model\n",
      "Epoch 7 \t\t Training Loss: 0.6464461641268687 \t\t Validation Loss: 0.6459365037621044\n",
      "Validation Loss Decreased(39.482859--->39.402127) \t Saving The Model\n",
      "Epoch 8 \t\t Training Loss: 0.6451202147715801 \t\t Validation Loss: 0.6446176093132769\n",
      "Validation Loss Decreased(39.402127--->39.321674) \t Saving The Model\n",
      "Epoch 9 \t\t Training Loss: 0.643798852826024 \t\t Validation Loss: 0.6433032682684602\n",
      "Validation Loss Decreased(39.321674--->39.241499) \t Saving The Model\n",
      "Epoch 10 \t\t Training Loss: 0.6424820240553435 \t\t Validation Loss: 0.6419934288400119\n",
      "Validation Loss Decreased(39.241499--->39.161599) \t Saving The Model\n",
      "Epoch 11 \t\t Training Loss: 0.6411696656330211 \t\t Validation Loss: 0.6406880402174152\n",
      "Validation Loss Decreased(39.161599--->39.081970) \t Saving The Model\n",
      "Epoch 12 \t\t Training Loss: 0.6398617453403301 \t\t Validation Loss: 0.6393870711326599\n",
      "Validation Loss Decreased(39.081970--->39.002611) \t Saving The Model\n",
      "Epoch 13 \t\t Training Loss: 0.6385582191450102 \t\t Validation Loss: 0.6380904365758426\n",
      "Validation Loss Decreased(39.002611--->38.923517) \t Saving The Model\n",
      "Epoch 14 \t\t Training Loss: 0.6372590145549258 \t\t Validation Loss: 0.6367980915991986\n",
      "Validation Loss Decreased(38.923517--->38.844684) \t Saving The Model\n",
      "Epoch 15 \t\t Training Loss: 0.6359640687435597 \t\t Validation Loss: 0.635509970735331\n",
      "Validation Loss Decreased(38.844684--->38.766108) \t Saving The Model\n",
      "Epoch 16 \t\t Training Loss: 0.6346733548619725 \t\t Validation Loss: 0.6342260857097438\n",
      "Validation Loss Decreased(38.766108--->38.687791) \t Saving The Model\n",
      "Epoch 17 \t\t Training Loss: 0.6333868363956073 \t\t Validation Loss: 0.632946358352411\n",
      "Validation Loss Decreased(38.687791--->38.609728) \t Saving The Model\n",
      "Epoch 18 \t\t Training Loss: 0.6321044918653127 \t\t Validation Loss: 0.6316707691208261\n",
      "Validation Loss Decreased(38.609728--->38.531917) \t Saving The Model\n",
      "Epoch 19 \t\t Training Loss: 0.6308262831455952 \t\t Validation Loss: 0.6303993238777411\n",
      "Validation Loss Decreased(38.531917--->38.454359) \t Saving The Model\n",
      "Epoch 20 \t\t Training Loss: 0.6295522102364549 \t\t Validation Loss: 0.629131980606767\n",
      "Validation Loss Decreased(38.454359--->38.377051) \t Saving The Model\n",
      "Epoch 21 \t\t Training Loss: 0.6282822199769922 \t\t Validation Loss: 0.6278687099941441\n",
      "Validation Loss Decreased(38.377051--->38.299991) \t Saving The Model\n",
      "Epoch 22 \t\t Training Loss: 0.6270163145151224 \t\t Validation Loss: 0.6266095042228699\n",
      "Validation Loss Decreased(38.299991--->38.223180) \t Saving The Model\n",
      "Epoch 23 \t\t Training Loss: 0.6257544734456517 \t\t Validation Loss: 0.6253543681785708\n",
      "Validation Loss Decreased(38.223180--->38.146616) \t Saving The Model\n",
      "Epoch 24 \t\t Training Loss: 0.6244966892508773 \t\t Validation Loss: 0.6241032578906075\n",
      "Validation Loss Decreased(38.146616--->38.070299) \t Saving The Model\n",
      "Epoch 25 \t\t Training Loss: 0.6232429624677779 \t\t Validation Loss: 0.622856225146622\n",
      "Validation Loss Decreased(38.070299--->37.994230) \t Saving The Model\n",
      "Epoch 26 \t\t Training Loss: 0.6219932984661412 \t\t Validation Loss: 0.6216132181589721\n",
      "Validation Loss Decreased(37.994230--->37.918406) \t Saving The Model\n",
      "Epoch 27 \t\t Training Loss: 0.6207476811366038 \t\t Validation Loss: 0.6203742672185428\n",
      "Validation Loss Decreased(37.918406--->37.842830) \t Saving The Model\n",
      "Epoch 28 \t\t Training Loss: 0.6195061314213384 \t\t Validation Loss: 0.6191393713482091\n",
      "Validation Loss Decreased(37.842830--->37.767502) \t Saving The Model\n",
      "Epoch 29 \t\t Training Loss: 0.6182686418026417 \t\t Validation Loss: 0.6179085403192238\n",
      "Validation Loss Decreased(37.767502--->37.692421) \t Saving The Model\n",
      "Epoch 30 \t\t Training Loss: 0.617035224631026 \t\t Validation Loss: 0.6166817839028406\n",
      "Validation Loss Decreased(37.692421--->37.617589) \t Saving The Model\n",
      "Epoch 31 \t\t Training Loss: 0.6158058879611729 \t\t Validation Loss: 0.615459105030435\n",
      "Validation Loss Decreased(37.617589--->37.543005) \t Saving The Model\n",
      "Epoch 32 \t\t Training Loss: 0.6145806409217216 \t\t Validation Loss: 0.614240508587634\n",
      "Validation Loss Decreased(37.543005--->37.468671) \t Saving The Model\n",
      "Epoch 33 \t\t Training Loss: 0.6133595023069296 \t\t Validation Loss: 0.6130260258424477\n",
      "Validation Loss Decreased(37.468671--->37.394588) \t Saving The Model\n",
      "Epoch 34 \t\t Training Loss: 0.6121424710428393 \t\t Validation Loss: 0.6118156382294951\n",
      "Validation Loss Decreased(37.394588--->37.320754) \t Saving The Model\n",
      "Epoch 35 \t\t Training Loss: 0.6109295557211111 \t\t Validation Loss: 0.6106093496572776\n",
      "Validation Loss Decreased(37.320754--->37.247170) \t Saving The Model\n",
      "Epoch 36 \t\t Training Loss: 0.6097207413063394 \t\t Validation Loss: 0.6094071611029203\n",
      "Validation Loss Decreased(37.247170--->37.173837) \t Saving The Model\n",
      "Epoch 37 \t\t Training Loss: 0.6085160358532055 \t\t Validation Loss: 0.6082090813605512\n",
      "Validation Loss Decreased(37.173837--->37.100754) \t Saving The Model\n",
      "Epoch 38 \t\t Training Loss: 0.6073154458054552 \t\t Validation Loss: 0.6070151143386716\n",
      "Validation Loss Decreased(37.100754--->37.027922) \t Saving The Model\n",
      "Epoch 39 \t\t Training Loss: 0.6061189921052607 \t\t Validation Loss: 0.6058252854425399\n",
      "Validation Loss Decreased(37.027922--->36.955342) \t Saving The Model\n",
      "Epoch 40 \t\t Training Loss: 0.6049266763635583 \t\t Validation Loss: 0.6046395956492815\n",
      "Validation Loss Decreased(36.955342--->36.883015) \t Saving The Model\n",
      "Epoch 41 \t\t Training Loss: 0.6037385243553299 \t\t Validation Loss: 0.6034580517987735\n",
      "Validation Loss Decreased(36.883015--->36.810941) \t Saving The Model\n",
      "Epoch 42 \t\t Training Loss: 0.6025545339326601 \t\t Validation Loss: 0.6022806763648987\n",
      "Validation Loss Decreased(36.810941--->36.739121) \t Saving The Model\n",
      "Epoch 43 \t\t Training Loss: 0.6013747002627399 \t\t Validation Loss: 0.6011074468737743\n",
      "Validation Loss Decreased(36.739121--->36.667554) \t Saving The Model\n",
      "Epoch 44 \t\t Training Loss: 0.6001990501945084 \t\t Validation Loss: 0.5999383975247867\n",
      "Validation Loss Decreased(36.667554--->36.596242) \t Saving The Model\n",
      "Epoch 45 \t\t Training Loss: 0.5990275590269415 \t\t Validation Loss: 0.5987735048669284\n",
      "Validation Loss Decreased(36.596242--->36.525184) \t Saving The Model\n",
      "Epoch 46 \t\t Training Loss: 0.597860260052724 \t\t Validation Loss: 0.5976127864884548\n",
      "Validation Loss Decreased(36.525184--->36.454380) \t Saving The Model\n",
      "Epoch 47 \t\t Training Loss: 0.5966971280338528 \t\t Validation Loss: 0.5964562521606195\n",
      "Validation Loss Decreased(36.454380--->36.383831) \t Saving The Model\n",
      "Epoch 48 \t\t Training Loss: 0.5955381994848853 \t\t Validation Loss: 0.5953039028605477\n",
      "Validation Loss Decreased(36.383831--->36.313538) \t Saving The Model\n",
      "Epoch 49 \t\t Training Loss: 0.5943834599073943 \t\t Validation Loss: 0.594155734679738\n",
      "Validation Loss Decreased(36.313538--->36.243500) \t Saving The Model\n",
      "Epoch 50 \t\t Training Loss: 0.5932329227258494 \t\t Validation Loss: 0.5930117798633263\n",
      "Validation Loss Decreased(36.243500--->36.173719) \t Saving The Model\n",
      "Epoch 51 \t\t Training Loss: 0.5920866072714865 \t\t Validation Loss: 0.5918720188688059\n",
      "Validation Loss Decreased(36.173719--->36.104193) \t Saving The Model\n",
      "Epoch 52 \t\t Training Loss: 0.5909444968979638 \t\t Validation Loss: 0.5907364653759315\n",
      "Validation Loss Decreased(36.104193--->36.034924) \t Saving The Model\n",
      "Epoch 53 \t\t Training Loss: 0.5898065959011112 \t\t Validation Loss: 0.5896051379500843\n",
      "Validation Loss Decreased(36.034924--->35.965913) \t Saving The Model\n",
      "Epoch 54 \t\t Training Loss: 0.5886729445543375 \t\t Validation Loss: 0.5884780317056374\n",
      "Validation Loss Decreased(35.965913--->35.897160) \t Saving The Model\n",
      "Epoch 55 \t\t Training Loss: 0.5875435305071307 \t\t Validation Loss: 0.5873551564138444\n",
      "Validation Loss Decreased(35.897160--->35.828665) \t Saving The Model\n",
      "Epoch 56 \t\t Training Loss: 0.5864183516115755 \t\t Validation Loss: 0.586236509143329\n",
      "Validation Loss Decreased(35.828665--->35.760427) \t Saving The Model\n",
      "Epoch 57 \t\t Training Loss: 0.5852974148483964 \t\t Validation Loss: 0.5851221094365979\n",
      "Validation Loss Decreased(35.760427--->35.692449) \t Saving The Model\n",
      "Epoch 58 \t\t Training Loss: 0.5841807341790414 \t\t Validation Loss: 0.5840119582707765\n",
      "Validation Loss Decreased(35.692449--->35.624729) \t Saving The Model\n",
      "Epoch 59 \t\t Training Loss: 0.5830682902722746 \t\t Validation Loss: 0.582906030240606\n",
      "Validation Loss Decreased(35.624729--->35.557268) \t Saving The Model\n",
      "Epoch 60 \t\t Training Loss: 0.5819601019223531 \t\t Validation Loss: 0.5818043351173401\n",
      "Validation Loss Decreased(35.557268--->35.490064) \t Saving The Model\n",
      "Epoch 61 \t\t Training Loss: 0.580856147113147 \t\t Validation Loss: 0.5807068729009784\n",
      "Validation Loss Decreased(35.490064--->35.423119) \t Saving The Model\n",
      "Epoch 62 \t\t Training Loss: 0.5797564419540199 \t\t Validation Loss: 0.5796136572712758\n",
      "Validation Loss Decreased(35.423119--->35.356433) \t Saving The Model\n",
      "Epoch 63 \t\t Training Loss: 0.5786609944996534 \t\t Validation Loss: 0.5785246911596079\n",
      "Validation Loss Decreased(35.356433--->35.290006) \t Saving The Model\n",
      "Epoch 64 \t\t Training Loss: 0.5775697993802594 \t\t Validation Loss: 0.5774399726117243\n",
      "Validation Loss Decreased(35.290006--->35.223838) \t Saving The Model\n",
      "Epoch 65 \t\t Training Loss: 0.5764828506890718 \t\t Validation Loss: 0.5763594703596147\n",
      "Validation Loss Decreased(35.223838--->35.157928) \t Saving The Model\n",
      "Epoch 66 \t\t Training Loss: 0.5754001586286871 \t\t Validation Loss: 0.5752832420536729\n",
      "Validation Loss Decreased(35.157928--->35.092278) \t Saving The Model\n",
      "Epoch 67 \t\t Training Loss: 0.5743217081636995 \t\t Validation Loss: 0.5742112173408759\n",
      "Validation Loss Decreased(35.092278--->35.026884) \t Saving The Model\n",
      "Epoch 68 \t\t Training Loss: 0.5732474982201516 \t\t Validation Loss: 0.5731434353062363\n",
      "Validation Loss Decreased(35.026884--->34.961750) \t Saving The Model\n",
      "Epoch 69 \t\t Training Loss: 0.5721775191324251 \t\t Validation Loss: 0.5720798812928747\n",
      "Validation Loss Decreased(34.961750--->34.896873) \t Saving The Model\n",
      "Epoch 70 \t\t Training Loss: 0.5711117676786475 \t\t Validation Loss: 0.5710205181700284\n",
      "Validation Loss Decreased(34.896873--->34.832252) \t Saving The Model\n",
      "Epoch 71 \t\t Training Loss: 0.5700502465437124 \t\t Validation Loss: 0.5699653889312118\n",
      "Validation Loss Decreased(34.832252--->34.767889) \t Saving The Model\n",
      "Epoch 72 \t\t Training Loss: 0.5689929310265962 \t\t Validation Loss: 0.5689144564456627\n",
      "Validation Loss Decreased(34.767889--->34.703782) \t Saving The Model\n",
      "Epoch 73 \t\t Training Loss: 0.567939830255938 \t\t Validation Loss: 0.5678677050793757\n",
      "Validation Loss Decreased(34.703782--->34.639930) \t Saving The Model\n",
      "Epoch 74 \t\t Training Loss: 0.5668909050322868 \t\t Validation Loss: 0.5668251250610977\n",
      "Validation Loss Decreased(34.639930--->34.576333) \t Saving The Model\n",
      "Epoch 75 \t\t Training Loss: 0.5658461720019847 \t\t Validation Loss: 0.5657867281163325\n",
      "Validation Loss Decreased(34.576333--->34.512990) \t Saving The Model\n",
      "Epoch 76 \t\t Training Loss: 0.5648056118337957 \t\t Validation Loss: 0.5647524927483231\n",
      "Validation Loss Decreased(34.512990--->34.449902) \t Saving The Model\n",
      "Epoch 77 \t\t Training Loss: 0.5637692358042743 \t\t Validation Loss: 0.5637224375224504\n",
      "Validation Loss Decreased(34.449902--->34.387069) \t Saving The Model\n",
      "Epoch 78 \t\t Training Loss: 0.5627370578748686 \t\t Validation Loss: 0.5626965575530881\n",
      "Validation Loss Decreased(34.387069--->34.324490) \t Saving The Model\n",
      "Epoch 79 \t\t Training Loss: 0.5617090651580879 \t\t Validation Loss: 0.5616748684742412\n",
      "Validation Loss Decreased(34.324490--->34.262167) \t Saving The Model\n",
      "Epoch 80 \t\t Training Loss: 0.560685270541423 \t\t Validation Loss: 0.5606573800571629\n",
      "Validation Loss Decreased(34.262167--->34.200100) \t Saving The Model\n",
      "Epoch 81 \t\t Training Loss: 0.5596656745618528 \t\t Validation Loss: 0.5596440649423443\n",
      "Validation Loss Decreased(34.200100--->34.138288) \t Saving The Model\n",
      "Epoch 82 \t\t Training Loss: 0.5586502664798015 \t\t Validation Loss: 0.5586349182441587\n",
      "Validation Loss Decreased(34.138288--->34.076730) \t Saving The Model\n",
      "Epoch 83 \t\t Training Loss: 0.557639044147354 \t\t Validation Loss: 0.5576299741619923\n",
      "Validation Loss Decreased(34.076730--->34.015428) \t Saving The Model\n",
      "Epoch 84 \t\t Training Loss: 0.556632023136895 \t\t Validation Loss: 0.5566292024049603\n",
      "Validation Loss Decreased(34.015428--->33.954381) \t Saving The Model\n",
      "Epoch 85 \t\t Training Loss: 0.5556292141880002 \t\t Validation Loss: 0.5556326322868222\n",
      "Validation Loss Decreased(33.954381--->33.893591) \t Saving The Model\n",
      "Epoch 86 \t\t Training Loss: 0.5546305942105817 \t\t Validation Loss: 0.5546402384023197\n",
      "Validation Loss Decreased(33.893591--->33.833055) \t Saving The Model\n",
      "Epoch 87 \t\t Training Loss: 0.5536361556869369 \t\t Validation Loss: 0.5536520246599541\n",
      "Validation Loss Decreased(33.833055--->33.772774) \t Saving The Model\n",
      "Epoch 88 \t\t Training Loss: 0.5526459158003867 \t\t Validation Loss: 0.5526679939911013\n",
      "Validation Loss Decreased(33.772774--->33.712748) \t Saving The Model\n",
      "Epoch 89 \t\t Training Loss: 0.5516598595155252 \t\t Validation Loss: 0.5516881327160069\n",
      "Validation Loss Decreased(33.712748--->33.652976) \t Saving The Model\n",
      "Epoch 90 \t\t Training Loss: 0.5506779750188192 \t\t Validation Loss: 0.5507124212921642\n",
      "Validation Loss Decreased(33.652976--->33.593458) \t Saving The Model\n",
      "Epoch 91 \t\t Training Loss: 0.5497002456639264 \t\t Validation Loss: 0.5497408499483203\n",
      "Validation Loss Decreased(33.593458--->33.534192) \t Saving The Model\n",
      "Epoch 92 \t\t Training Loss: 0.5487266709138682 \t\t Validation Loss: 0.548773425524352\n",
      "Validation Loss Decreased(33.534192--->33.475179) \t Saving The Model\n",
      "Epoch 93 \t\t Training Loss: 0.5477572405660475 \t\t Validation Loss: 0.5478101226150013\n",
      "Validation Loss Decreased(33.475179--->33.416417) \t Saving The Model\n",
      "Epoch 94 \t\t Training Loss: 0.5467919315303769 \t\t Validation Loss: 0.5468509177692601\n",
      "Validation Loss Decreased(33.416417--->33.357906) \t Saving The Model\n",
      "Epoch 95 \t\t Training Loss: 0.5458307201797897 \t\t Validation Loss: 0.545895797307374\n",
      "Validation Loss Decreased(33.357906--->33.299644) \t Saving The Model\n",
      "Epoch 96 \t\t Training Loss: 0.5448735925528381 \t\t Validation Loss: 0.544944739732586\n",
      "Validation Loss Decreased(33.299644--->33.241629) \t Saving The Model\n",
      "Epoch 97 \t\t Training Loss: 0.5439205255594339 \t\t Validation Loss: 0.5439977108455095\n",
      "Validation Loss Decreased(33.241629--->33.183860) \t Saving The Model\n",
      "Epoch 98 \t\t Training Loss: 0.5429714955725111 \t\t Validation Loss: 0.5430547106461446\n",
      "Validation Loss Decreased(33.183860--->33.126337) \t Saving The Model\n",
      "Epoch 99 \t\t Training Loss: 0.542026479501982 \t\t Validation Loss: 0.5421156912553505\n",
      "Validation Loss Decreased(33.126337--->33.069057) \t Saving The Model\n",
      "Epoch 100 \t\t Training Loss: 0.5410854521098437 \t\t Validation Loss: 0.5411806419247487\n",
      "Validation Loss Decreased(33.069057--->33.012019) \t Saving The Model\n"
     ]
    }
   ],
   "source": [
    "Named_Entity_Recognition(train, valid, r'skip_negative.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataLoader(load_dataset(main_dict_test,word_embedding), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the model are:\n",
      "[[3263.    0.]\n",
      " [ 200.    0.]]\n",
      "Accuracy: 0.9422466069881605\n",
      "Precision: 1.0\n",
      "Recall: 0.9422466069881605\n",
      "F1 Score: 0.9702646446625037\n"
     ]
    }
   ],
   "source": [
    "evaluate(test, r'skip_negative.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOVE with Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = Word2Vec.load(r'glove_with_negative_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(load_dataset(main_dict,word_embedding), batch_size=64)\n",
    "valid = DataLoader(load_dataset(main_dict_valid,word_embedding), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: \n",
      "35252\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]          30,100\n",
      "           Sigmoid-2               [-1, 1, 100]               0\n",
      "            Linear-3                [-1, 1, 50]           5,050\n",
      "           Sigmoid-4                [-1, 1, 50]               0\n",
      "            Linear-5                 [-1, 1, 2]             102\n",
      "           Sigmoid-6                 [-1, 1, 2]               0\n",
      "================================================================\n",
      "Total params: 35,252\n",
      "Trainable params: 35,252\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.14\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Epoch 1 \t\t Training Loss: 0.6699392086750752 \t\t Validation Loss: 0.6693937006543894\n",
      "Validation Loss Decreased(inf--->40.833016) \t Saving The Model\n",
      "Epoch 2 \t\t Training Loss: 0.6687042149337562 \t\t Validation Loss: 0.6681648932519506\n",
      "Validation Loss Decreased(40.833016--->40.758058) \t Saving The Model\n",
      "Epoch 3 \t\t Training Loss: 0.667473350559269 \t\t Validation Loss: 0.6669401956386254\n",
      "Validation Loss Decreased(40.758058--->40.683352) \t Saving The Model\n",
      "Epoch 4 \t\t Training Loss: 0.6662465382266689 \t\t Validation Loss: 0.6657196674190584\n",
      "Validation Loss Decreased(40.683352--->40.608900) \t Saving The Model\n",
      "Epoch 5 \t\t Training Loss: 0.6650238198203009 \t\t Validation Loss: 0.6645032665768608\n",
      "Validation Loss Decreased(40.608900--->40.534699) \t Saving The Model\n",
      "Epoch 6 \t\t Training Loss: 0.663805227558892 \t\t Validation Loss: 0.6632909647753982\n",
      "Validation Loss Decreased(40.534699--->40.460749) \t Saving The Model\n",
      "Epoch 7 \t\t Training Loss: 0.6625907243909063 \t\t Validation Loss: 0.6620827688545478\n",
      "Validation Loss Decreased(40.460749--->40.387049) \t Saving The Model\n",
      "Epoch 8 \t\t Training Loss: 0.6613802888371922 \t\t Validation Loss: 0.6608786065070356\n",
      "Validation Loss Decreased(40.387049--->40.313595) \t Saving The Model\n",
      "Epoch 9 \t\t Training Loss: 0.6601738935118323 \t\t Validation Loss: 0.6596784513504779\n",
      "Validation Loss Decreased(40.313595--->40.240386) \t Saving The Model\n",
      "Epoch 10 \t\t Training Loss: 0.6589714965304813 \t\t Validation Loss: 0.6584822760253656\n",
      "Validation Loss Decreased(40.240386--->40.167419) \t Saving The Model\n",
      "Epoch 11 \t\t Training Loss: 0.6577730506390065 \t\t Validation Loss: 0.6572900365610592\n",
      "Validation Loss Decreased(40.167419--->40.094692) \t Saving The Model\n",
      "Epoch 12 \t\t Training Loss: 0.656578533284299 \t\t Validation Loss: 0.6561016987581723\n",
      "Validation Loss Decreased(40.094692--->40.022204) \t Saving The Model\n",
      "Epoch 13 \t\t Training Loss: 0.6553878853986929 \t\t Validation Loss: 0.654917194217932\n",
      "Validation Loss Decreased(40.022204--->39.949949) \t Saving The Model\n",
      "Epoch 14 \t\t Training Loss: 0.6542010645608645 \t\t Validation Loss: 0.6537364994893309\n",
      "Validation Loss Decreased(39.949949--->39.877926) \t Saving The Model\n",
      "Epoch 15 \t\t Training Loss: 0.6530180331822988 \t\t Validation Loss: 0.6525595500820973\n",
      "Validation Loss Decreased(39.877926--->39.806133) \t Saving The Model\n",
      "Epoch 16 \t\t Training Loss: 0.6518387466937572 \t\t Validation Loss: 0.6513863069112183\n",
      "Validation Loss Decreased(39.806133--->39.734565) \t Saving The Model\n",
      "Epoch 17 \t\t Training Loss: 0.6506631250854011 \t\t Validation Loss: 0.6502167133034252\n",
      "Validation Loss Decreased(39.734565--->39.663220) \t Saving The Model\n",
      "Epoch 18 \t\t Training Loss: 0.649491117881225 \t\t Validation Loss: 0.6490506783860629\n",
      "Validation Loss Decreased(39.663220--->39.592091) \t Saving The Model\n",
      "Epoch 19 \t\t Training Loss: 0.6483226649396054 \t\t Validation Loss: 0.6478881581884915\n",
      "Validation Loss Decreased(39.592091--->39.521178) \t Saving The Model\n",
      "Epoch 20 \t\t Training Loss: 0.6471577045079824 \t\t Validation Loss: 0.6467291146028237\n",
      "Validation Loss Decreased(39.521178--->39.450476) \t Saving The Model\n",
      "Epoch 21 \t\t Training Loss: 0.6459961807405626 \t\t Validation Loss: 0.6455734684819081\n",
      "Validation Loss Decreased(39.450476--->39.379982) \t Saving The Model\n",
      "Epoch 22 \t\t Training Loss: 0.6448380512160223 \t\t Validation Loss: 0.6444211885577342\n",
      "Validation Loss Decreased(39.379982--->39.309693) \t Saving The Model\n",
      "Epoch 23 \t\t Training Loss: 0.6436832842526136 \t\t Validation Loss: 0.6432722337910386\n",
      "Validation Loss Decreased(39.309693--->39.239606) \t Saving The Model\n",
      "Epoch 24 \t\t Training Loss: 0.6425318309852669 \t\t Validation Loss: 0.6421266061360719\n",
      "Validation Loss Decreased(39.239606--->39.169723) \t Saving The Model\n",
      "Epoch 25 \t\t Training Loss: 0.6413837118191762 \t\t Validation Loss: 0.640984299730082\n",
      "Validation Loss Decreased(39.169723--->39.100042) \t Saving The Model\n",
      "Epoch 26 \t\t Training Loss: 0.6402389149408083 \t\t Validation Loss: 0.6398453028475652\n",
      "Validation Loss Decreased(39.100042--->39.030563) \t Saving The Model\n",
      "Epoch 27 \t\t Training Loss: 0.6390974161861179 \t\t Validation Loss: 0.6387096018087669\n",
      "Validation Loss Decreased(39.030563--->38.961286) \t Saving The Model\n",
      "Epoch 28 \t\t Training Loss: 0.6379592144811476 \t\t Validation Loss: 0.6375771956365617\n",
      "Validation Loss Decreased(38.961286--->38.892209) \t Saving The Model\n",
      "Epoch 29 \t\t Training Loss: 0.6368243168066213 \t\t Validation Loss: 0.6364480452459367\n",
      "Validation Loss Decreased(38.892209--->38.823331) \t Saving The Model\n",
      "Epoch 30 \t\t Training Loss: 0.6356926898698549 \t\t Validation Loss: 0.6353221740878996\n",
      "Validation Loss Decreased(38.823331--->38.754653) \t Saving The Model\n",
      "Epoch 31 \t\t Training Loss: 0.6345643245422088 \t\t Validation Loss: 0.6341995596885681\n",
      "Validation Loss Decreased(38.754653--->38.686173) \t Saving The Model\n",
      "Epoch 32 \t\t Training Loss: 0.6334391988075532 \t\t Validation Loss: 0.633080144397548\n",
      "Validation Loss Decreased(38.686173--->38.617889) \t Saving The Model\n",
      "Epoch 33 \t\t Training Loss: 0.6323172944086092 \t\t Validation Loss: 0.6319639565514736\n",
      "Validation Loss Decreased(38.617889--->38.549801) \t Saving The Model\n",
      "Epoch 34 \t\t Training Loss: 0.6311985904032046 \t\t Validation Loss: 0.6308509658594601\n",
      "Validation Loss Decreased(38.549801--->38.481909) \t Saving The Model\n",
      "Epoch 35 \t\t Training Loss: 0.6300830722929122 \t\t Validation Loss: 0.6297411254194917\n",
      "Validation Loss Decreased(38.481909--->38.414209) \t Saving The Model\n",
      "Epoch 36 \t\t Training Loss: 0.6289707212834745 \t\t Validation Loss: 0.628634437185819\n",
      "Validation Loss Decreased(38.414209--->38.346701) \t Saving The Model\n",
      "Epoch 37 \t\t Training Loss: 0.6278614938796103 \t\t Validation Loss: 0.6275308591420533\n",
      "Validation Loss Decreased(38.346701--->38.279382) \t Saving The Model\n",
      "Epoch 38 \t\t Training Loss: 0.6267553852485107 \t\t Validation Loss: 0.6264303678371868\n",
      "Validation Loss Decreased(38.279382--->38.212252) \t Saving The Model\n",
      "Epoch 39 \t\t Training Loss: 0.6256523416922973 \t\t Validation Loss: 0.6253329251633316\n",
      "Validation Loss Decreased(38.212252--->38.145308) \t Saving The Model\n",
      "Epoch 40 \t\t Training Loss: 0.624552346564628 \t\t Validation Loss: 0.6242385213492346\n",
      "Validation Loss Decreased(38.145308--->38.078550) \t Saving The Model\n",
      "Epoch 41 \t\t Training Loss: 0.6234553783863515 \t\t Validation Loss: 0.6231471348981388\n",
      "Validation Loss Decreased(38.078550--->38.011975) \t Saving The Model\n",
      "Epoch 42 \t\t Training Loss: 0.6223614344725737 \t\t Validation Loss: 0.6220587540845401\n",
      "Validation Loss Decreased(38.011975--->37.945584) \t Saving The Model\n",
      "Epoch 43 \t\t Training Loss: 0.6212704944181012 \t\t Validation Loss: 0.6209733740228122\n",
      "Validation Loss Decreased(37.945584--->37.879376) \t Saving The Model\n",
      "Epoch 44 \t\t Training Loss: 0.6201825592968915 \t\t Validation Loss: 0.6198909995985813\n",
      "Validation Loss Decreased(37.879376--->37.813351) \t Saving The Model\n",
      "Epoch 45 \t\t Training Loss: 0.6190976414594564 \t\t Validation Loss: 0.6188116425373515\n",
      "Validation Loss Decreased(37.813351--->37.747510) \t Saving The Model\n",
      "Epoch 46 \t\t Training Loss: 0.6180157639958836 \t\t Validation Loss: 0.61773532433588\n",
      "Validation Loss Decreased(37.747510--->37.681855) \t Saving The Model\n",
      "Epoch 47 \t\t Training Loss: 0.6169369209994067 \t\t Validation Loss: 0.6166620362000387\n",
      "Validation Loss Decreased(37.681855--->37.616384) \t Saving The Model\n",
      "Epoch 48 \t\t Training Loss: 0.6158611344861554 \t\t Validation Loss: 0.6155918221004674\n",
      "Validation Loss Decreased(37.616384--->37.551101) \t Saving The Model\n",
      "Epoch 49 \t\t Training Loss: 0.6147884114368541 \t\t Validation Loss: 0.6145246576090329\n",
      "Validation Loss Decreased(37.551101--->37.486004) \t Saving The Model\n",
      "Epoch 50 \t\t Training Loss: 0.6137187411119273 \t\t Validation Loss: 0.6134605407714844\n",
      "Validation Loss Decreased(37.486004--->37.421093) \t Saving The Model\n",
      "Epoch 51 \t\t Training Loss: 0.6126521562670803 \t\t Validation Loss: 0.6123994989473311\n",
      "Validation Loss Decreased(37.421093--->37.356369) \t Saving The Model\n",
      "Epoch 52 \t\t Training Loss: 0.6115886230726499 \t\t Validation Loss: 0.6113415184568186\n",
      "Validation Loss Decreased(37.356369--->37.291833) \t Saving The Model\n",
      "Epoch 53 \t\t Training Loss: 0.6105281785801724 \t\t Validation Loss: 0.6102866295908318\n",
      "Validation Loss Decreased(37.291833--->37.227484) \t Saving The Model\n",
      "Epoch 54 \t\t Training Loss: 0.6094707900339419 \t\t Validation Loss: 0.6092347737218513\n",
      "Validation Loss Decreased(37.227484--->37.163321) \t Saving The Model\n",
      "Epoch 55 \t\t Training Loss: 0.6084164815980035 \t\t Validation Loss: 0.6081859850492634\n",
      "Validation Loss Decreased(37.163321--->37.099345) \t Saving The Model\n",
      "Epoch 56 \t\t Training Loss: 0.6073652172947789 \t\t Validation Loss: 0.6071402381678097\n",
      "Validation Loss Decreased(37.099345--->37.035555) \t Saving The Model\n",
      "Epoch 57 \t\t Training Loss: 0.6063169933654167 \t\t Validation Loss: 0.606097514512109\n",
      "Validation Loss Decreased(37.035555--->36.971948) \t Saving The Model\n",
      "Epoch 58 \t\t Training Loss: 0.6052717808130625 \t\t Validation Loss: 0.6050577935625295\n",
      "Validation Loss Decreased(36.971948--->36.908525) \t Saving The Model\n",
      "Epoch 59 \t\t Training Loss: 0.6042295919882285 \t\t Validation Loss: 0.6040210919302018\n",
      "Validation Loss Decreased(36.908525--->36.845287) \t Saving The Model\n",
      "Epoch 60 \t\t Training Loss: 0.6031904360195538 \t\t Validation Loss: 0.6029874037523739\n",
      "Validation Loss Decreased(36.845287--->36.782232) \t Saving The Model\n",
      "Epoch 61 \t\t Training Loss: 0.6021542758555025 \t\t Validation Loss: 0.6019567143721659\n",
      "Validation Loss Decreased(36.782232--->36.719360) \t Saving The Model\n",
      "Epoch 62 \t\t Training Loss: 0.6011211308273109 \t\t Validation Loss: 0.6009290482177109\n",
      "Validation Loss Decreased(36.719360--->36.656672) \t Saving The Model\n",
      "Epoch 63 \t\t Training Loss: 0.6000910057677878 \t\t Validation Loss: 0.599904396494881\n",
      "Validation Loss Decreased(36.656672--->36.594168) \t Saving The Model\n",
      "Epoch 64 \t\t Training Loss: 0.5990639345065968 \t\t Validation Loss: 0.598882788517436\n",
      "Validation Loss Decreased(36.594168--->36.531850) \t Saving The Model\n",
      "Epoch 65 \t\t Training Loss: 0.5980399138218647 \t\t Validation Loss: 0.5978642477363837\n",
      "Validation Loss Decreased(36.531850--->36.469719) \t Saving The Model\n",
      "Epoch 66 \t\t Training Loss: 0.597018963581807 \t\t Validation Loss: 0.5968487849001025\n",
      "Validation Loss Decreased(36.469719--->36.407776) \t Saving The Model\n",
      "Epoch 67 \t\t Training Loss: 0.5960011031176593 \t\t Validation Loss: 0.5958364136883469\n",
      "Validation Loss Decreased(36.407776--->36.346021) \t Saving The Model\n",
      "Epoch 68 \t\t Training Loss: 0.5949863501497217 \t\t Validation Loss: 0.59482712726124\n",
      "Validation Loss Decreased(36.346021--->36.284455) \t Saving The Model\n",
      "Epoch 69 \t\t Training Loss: 0.5939747057519518 \t\t Validation Loss: 0.593820963726669\n",
      "Validation Loss Decreased(36.284455--->36.223079) \t Saving The Model\n",
      "Epoch 70 \t\t Training Loss: 0.5929661790529887 \t\t Validation Loss: 0.5928179123362557\n",
      "Validation Loss Decreased(36.223079--->36.161893) \t Saving The Model\n",
      "Epoch 71 \t\t Training Loss: 0.5919607866991747 \t\t Validation Loss: 0.5918180297632687\n",
      "Validation Loss Decreased(36.161893--->36.100900) \t Saving The Model\n",
      "Epoch 72 \t\t Training Loss: 0.5909585668160034 \t\t Validation Loss: 0.5908212769226949\n",
      "Validation Loss Decreased(36.100900--->36.040098) \t Saving The Model\n",
      "Epoch 73 \t\t Training Loss: 0.5899594979243236 \t\t Validation Loss: 0.589827699739425\n",
      "Validation Loss Decreased(36.040098--->35.979490) \t Saving The Model\n",
      "Epoch 74 \t\t Training Loss: 0.5889636079470316 \t\t Validation Loss: 0.5888372718310747\n",
      "Validation Loss Decreased(35.979490--->35.919074) \t Saving The Model\n",
      "Epoch 75 \t\t Training Loss: 0.5879708764789341 \t\t Validation Loss: 0.5878500234885294\n",
      "Validation Loss Decreased(35.919074--->35.858851) \t Saving The Model\n",
      "Epoch 76 \t\t Training Loss: 0.5869813394976092 \t\t Validation Loss: 0.5868659654601676\n",
      "Validation Loss Decreased(35.858851--->35.798824) \t Saving The Model\n",
      "Epoch 77 \t\t Training Loss: 0.5859949825046299 \t\t Validation Loss: 0.5858850567067255\n",
      "Validation Loss Decreased(35.798824--->35.738988) \t Saving The Model\n",
      "Epoch 78 \t\t Training Loss: 0.5850118081848901 \t\t Validation Loss: 0.5849073392445924\n",
      "Validation Loss Decreased(35.738988--->35.679348) \t Saving The Model\n",
      "Epoch 79 \t\t Training Loss: 0.5840318240560927 \t\t Validation Loss: 0.5839328238221465\n",
      "Validation Loss Decreased(35.679348--->35.619902) \t Saving The Model\n",
      "Epoch 80 \t\t Training Loss: 0.5830550413947921 \t\t Validation Loss: 0.5829614918740069\n",
      "Validation Loss Decreased(35.619902--->35.560651) \t Saving The Model\n",
      "Epoch 81 \t\t Training Loss: 0.5820814483874553 \t\t Validation Loss: 0.581993326789043\n",
      "Validation Loss Decreased(35.560651--->35.501593) \t Saving The Model\n",
      "Epoch 82 \t\t Training Loss: 0.5811110294616975 \t\t Validation Loss: 0.5810283275901295\n",
      "Validation Loss Decreased(35.501593--->35.442728) \t Saving The Model\n",
      "Epoch 83 \t\t Training Loss: 0.5801437846175185 \t\t Validation Loss: 0.5800664952543916\n",
      "Validation Loss Decreased(35.442728--->35.384056) \t Saving The Model\n",
      "Epoch 84 \t\t Training Loss: 0.5791797025783642 \t\t Validation Loss: 0.5791078297818293\n",
      "Validation Loss Decreased(35.384056--->35.325578) \t Saving The Model\n",
      "Epoch 85 \t\t Training Loss: 0.5782187811963193 \t\t Validation Loss: 0.5781523096756856\n",
      "Validation Loss Decreased(35.325578--->35.267291) \t Saving The Model\n",
      "Epoch 86 \t\t Training Loss: 0.5772610172495112 \t\t Validation Loss: 0.5771999320045846\n",
      "Validation Loss Decreased(35.267291--->35.209196) \t Saving The Model\n",
      "Epoch 87 \t\t Training Loss: 0.5763064026832581 \t\t Validation Loss: 0.5762506909057742\n",
      "Validation Loss Decreased(35.209196--->35.151292) \t Saving The Model\n",
      "Epoch 88 \t\t Training Loss: 0.575354903130918 \t\t Validation Loss: 0.5753045453399909\n",
      "Validation Loss Decreased(35.151292--->35.093577) \t Saving The Model\n",
      "Epoch 89 \t\t Training Loss: 0.5744065030201061 \t\t Validation Loss: 0.574361469901976\n",
      "Validation Loss Decreased(35.093577--->35.036050) \t Saving The Model\n",
      "Epoch 90 \t\t Training Loss: 0.5734611733539684 \t\t Validation Loss: 0.573421455797602\n",
      "Validation Loss Decreased(35.036050--->34.978709) \t Saving The Model\n",
      "Epoch 91 \t\t Training Loss: 0.5725189033929292 \t\t Validation Loss: 0.5724844903242393\n",
      "Validation Loss Decreased(34.978709--->34.921554) \t Saving The Model\n",
      "Epoch 92 \t\t Training Loss: 0.5715796555484738 \t\t Validation Loss: 0.5715505246256218\n",
      "Validation Loss Decreased(34.921554--->34.864582) \t Saving The Model\n",
      "Epoch 93 \t\t Training Loss: 0.5706433976018751 \t\t Validation Loss: 0.5706195215709874\n",
      "Validation Loss Decreased(34.864582--->34.807791) \t Saving The Model\n",
      "Epoch 94 \t\t Training Loss: 0.5697101027041942 \t\t Validation Loss: 0.5696914538008268\n",
      "Validation Loss Decreased(34.807791--->34.751179) \t Saving The Model\n",
      "Epoch 95 \t\t Training Loss: 0.5687797466913859 \t\t Validation Loss: 0.5687663134981374\n",
      "Validation Loss Decreased(34.751179--->34.694745) \t Saving The Model\n",
      "Epoch 96 \t\t Training Loss: 0.5678522984186808 \t\t Validation Loss: 0.5678440811204128\n",
      "Validation Loss Decreased(34.694745--->34.638489) \t Saving The Model\n",
      "Epoch 97 \t\t Training Loss: 0.5669277616449304 \t\t Validation Loss: 0.5669247302852694\n",
      "Validation Loss Decreased(34.638489--->34.582409) \t Saving The Model\n",
      "Epoch 98 \t\t Training Loss: 0.5660060966337049 \t\t Validation Loss: 0.5660082473129523\n",
      "Validation Loss Decreased(34.582409--->34.526503) \t Saving The Model\n",
      "Epoch 99 \t\t Training Loss: 0.5650873313079009 \t\t Validation Loss: 0.565094660540096\n",
      "Validation Loss Decreased(34.526503--->34.470774) \t Saving The Model\n",
      "Epoch 100 \t\t Training Loss: 0.5641714635196032 \t\t Validation Loss: 0.564183952378445\n",
      "Validation Loss Decreased(34.470774--->34.415221) \t Saving The Model\n"
     ]
    }
   ],
   "source": [
    "Named_Entity_Recognition(train, valid, r'glove_negative.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataLoader(load_dataset(main_dict_test,word_embedding), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the model are:\n",
      "[[3263.    0.]\n",
      " [ 200.    0.]]\n",
      "Accuracy: 0.9422466069881605\n",
      "Precision: 1.0\n",
      "Recall: 0.9422466069881605\n",
      "F1 Score: 0.9702646446625037\n"
     ]
    }
   ],
   "source": [
    "evaluate(test, r'glove_negative.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a01861876d126b30cd1b77ced19e532f706bc03e1154ffd933be16f6f668bcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
